import sqlite3
import pandas as pd
import itertools
import json
import os
import torch
from datetime import datetime
from typing import List, Dict, Any

# Chronosãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆç’°å¢ƒã«åˆã‚ã›ã¦ãƒ‘ã‚¹ã‚’é€šã—ã¦ãã ã•ã„ï¼‰
try:
    from chronos import Chronos2Pipeline
    # å­¦ç¿’ç”¨ã‚¯ãƒ©ã‚¹ãªã©ã¯å®Ÿéš›ã®å®Ÿè£…ã«åˆã‚ã›ã¦import
except ImportError:
    print("âš ï¸ Chronos library not found. Mocking for structure demonstration.")

class ExperimentRegistry:
    """ãƒ¡ã‚¿å®Ÿè¡Œè¡¨ï¼ˆDBï¼‰ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self, db_path="experiments.db"):
        self.db_path = db_path
        self._init_db()

    def _init_db(self):
        """ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        # å®Ÿé¨“ç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS experiments (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                model_name TEXT,
                task_type TEXT,          -- 'zero_shot', 'finetune', 'embedding', 'analysis'
                use_covariates BOOLEAN,  -- å¤–ç”Ÿå¤‰æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã‹
                context_length INTEGER,
                prediction_length INTEGER,
                num_samples INTEGER,     -- ç¢ºç‡äºˆæ¸¬ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
                cross_learning BOOLEAN,  -- ã‚¢ã‚¤ãƒ†ãƒ é–“ã‚¯ãƒ­ã‚¹å­¦ç¿’/æ¨è«–
                status TEXT DEFAULT 'TODO', -- 'TODO', 'RUNNING', 'DONE', 'ERROR'
                result_metrics JSON,     -- è©•ä¾¡çµæœ (MSE, WQLãªã©)
                output_path TEXT,        -- ä¿å­˜å…ˆãƒ‘ã‚¹
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        conn.commit()
        conn.close()

    def register_grid(self, param_grid: Dict[str, List[Any]]):
        """ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã®çµ„ã¿åˆã‚ã›ã‚’ç”Ÿæˆã—ã€æœªç™»éŒ²ãªã‚‰DBã«è¿½åŠ """
        keys = param_grid.keys()
        combinations = itertools.product(*param_grid.values())
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        count = 0
        for combo in combinations:
            params = dict(zip(keys, combo))
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆåŒã˜è¨­å®šãŒã™ã§ã«å­˜åœ¨ã™ã‚‹ã‹ï¼‰
            query = "SELECT id FROM experiments WHERE " + " AND ".join([f"{k}=?" for k in keys])
            cursor.execute(query, tuple(str(v) if isinstance(v, (list, dict)) else v for v in params.values()))
            
            if not cursor.fetchone():
                # æ–°è¦ç™»éŒ²
                cols = ", ".join(keys)
                placeholders = ", ".join(["?"] * len(keys))
                insert_sql = f"INSERT INTO experiments ({cols}) VALUES ({placeholders})"
                cursor.execute(insert_sql, tuple(params.values()))
                count += 1
        
        conn.commit()
        conn.close()
        print(f"âœ¨ Registered {count} new experiments.")

    def get_next_task(self):
        """æœªå®Ÿè¡Œ(TODO)ã®ã‚¿ã‚¹ã‚¯ã‚’1ã¤å–å¾—ã—ã¦RUNNINGã«ã™ã‚‹"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute("SELECT * FROM experiments WHERE status='TODO' LIMIT 1")
        row = cursor.fetchone()
        
        if row:
            task = dict(row)
            cursor.execute("UPDATE experiments SET status='RUNNING', updated_at=CURRENT_TIMESTAMP WHERE id=?", (task['id'],))
            conn.commit()
            conn.close()
            return task
        
        conn.close()
        return None

    def update_task_result(self, task_id, status, metrics=None, output_path=None):
        """å®Ÿè¡Œçµæœã‚’ä¿å­˜"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        metrics_json = json.dumps(metrics) if metrics else None
        cursor.execute('''
            UPDATE experiments 
            SET status=?, result_metrics=?, output_path=?, updated_at=CURRENT_TIMESTAMP 
            WHERE id=?
        ''', (status, metrics_json, output_path, task_id))
        
        conn.commit()
        conn.close()

class ChronosExecutor:
    """Chronos-2ã®å„æ©Ÿèƒ½ã‚’å®Ÿè¡Œã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, data_dir="libs/chronos/00_raw"):
        self.data_dir = data_dir
    
    def load_data(self, use_covariates: bool):
        """ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†ï¼ˆMockï¼‰"""
        # ã“ã“ã§ pandas.read_csv ç­‰ã‚’è¡Œã„ã€Chronos2Datasetå½¢å¼ã«å¤‰æ›
        print(f"   Dataset loading... (Covariates: {use_covariates})")
        return {"train": None, "test": None} # å®Ÿè£…æ™‚ã¯DataFrameç­‰ã‚’è¿”ã™

    def execute(self, task: Dict[str, Any]):
        """ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†ã®æŒ¯ã‚Šåˆ†ã‘"""
        task_id = task['id']
        task_type = task['task_type']
        
        print(f"ğŸš€ Processing Task ID: {task_id} | Type: {task_type}")
        
        try:
            # 1. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            data = self.load_data(task['use_covariates'])
            
            # 2. æ©Ÿèƒ½åˆ¥å®Ÿè¡Œ
            if task_type == 'zero_shot':
                result = self._run_zero_shot(task, data)
            elif task_type == 'finetune':
                result = self._run_finetune(task, data)
            elif task_type == 'embedding':
                result = self._run_embedding(task, data)
            elif task_type == 'analysis':
                result = self._run_covariate_analysis(task, data)
            else:
                raise ValueError(f"Unknown task type: {task_type}")
                
            return "DONE", result, f"outputs/{task_id}"
            
        except Exception as e:
            print(f"âŒ Error in task {task_id}: {e}")
            import traceback
            traceback.print_exc()
            return "ERROR", {"error": str(e)}, None

    def _run_zero_shot(self, task, data):
        """ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆäºˆæ¸¬ & è©•ä¾¡"""
        print("   Running Zero-shot Inference...")
        # pipeline = Chronos2Pipeline.from_pretrained(task['model_name'])
        # preds = pipeline.predict(...)
        # metrics = calculate_metrics(preds, data['test'])
        return {"mse": 0.05, "wql": 0.02} # Mock result

    def _run_finetune(self, task, data):
        """ãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ & ä¿å­˜"""
        print("   Running Fine-tuning...")
        # trainer = Chronos2Trainer(...)
        # trainer.train()
        # trainer.save_model(...)
        return {"training_loss": 0.01, "validation_loss": 0.02}

    def _run_embedding(self, task, data):
        """åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«ã‚ˆã‚‹ç‰¹å¾´é‡ä½œæˆ"""
        print("   Extracting Embeddings...")
        # model = Chronos2Model.from_pretrained(...)
        # embeddings = model.encode(data['train'])
        return {"embedding_shape": [100, 768], "saved_at": "embeddings.pt"}

    def _run_covariate_analysis(self, task, data):
        """å¤–ç”Ÿå¤‰æ•°ã®å¯„ä¸ç‡è§£æï¼ˆSensitivity Analysisï¼‰"""
        print("   Analyzing Covariate Contribution...")
        # 1. å…¨å¤‰æ•°ã‚ã‚Šã§äºˆæ¸¬
        # 2. ç‰¹å®šã®å¤–ç”Ÿå¤‰æ•°ã‚’0ã¾ãŸã¯ãƒ©ãƒ³ãƒ€ãƒ ã«ã—ã¦äºˆæ¸¬
        # 3. äºˆæ¸¬çµæœã®ã‚ºãƒ¬ï¼ˆDeltaï¼‰ã‚’å¯„ä¸ç‡ã¨ã™ã‚‹
        return {"covariate_importance": {"price": 0.4, "temperature": 0.1}}

# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯ ---
if __name__ == "__main__":
    # 1. DBç®¡ç†ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
    registry = ExperimentRegistry()
    
    # 2. ã‚°ãƒªãƒƒãƒ‰ãƒªã‚µãƒ¼ãƒã®è¨­å®šï¼ˆå®Ÿè¡Œã—ãŸã„å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    param_grid = {
        "model_name": ["amazon/chronos-t5-small"],
        "task_type": ["zero_shot", "finetune", "embedding", "analysis"],
        "use_covariates": [True, False],
        "context_length": [512],
        "prediction_length": [24],
        "cross_learning": [True, False] # ã‚¢ã‚¤ãƒ†ãƒ é–“å­¦ç¿’ã®æœ‰ç„¡
    }
    
    # 3. æœªç™»éŒ²ã®å®Ÿé¨“ã‚’DBã«ç™»éŒ²ï¼ˆå·®åˆ†ã®ã¿è¿½åŠ ï¼‰
    registry.register_grid(param_grid)
    
    # 4. ã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿ã®åˆæœŸåŒ–
    executor = ChronosExecutor()
    
    # 5. æœªå®Ÿè¡Œã‚¿ã‚¹ã‚¯ã®ãƒ«ãƒ¼ãƒ—å®Ÿè¡Œ
    while True:
        task = registry.get_next_task()
        if not task:
            print("ğŸ‰ All tasks completed!")
            break
            
        status, metrics, output_path = executor.execute(task)
        registry.update_task_result(task['id'], status, metrics, output_path)

    # 6. çµæœç¢ºèªï¼ˆç°¡æ˜“è¡¨ç¤ºï¼‰
    conn = sqlite3.connect("experiments.db")
    df = pd.read_sql("SELECT * FROM experiments", conn)
    print("\n=== ğŸ“Š Meta Execution Table Status ===")
    print(df[['id', 'task_type', 'use_covariates', 'status', 'result_metrics']].to_string())
    conn.close()