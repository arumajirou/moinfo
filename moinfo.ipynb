{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed851aa",
   "metadata": {},
   "source": [
    "## TimesFM（timesfm）公開API（関数・クラス）一覧を自動収集\n",
    "\n",
    "`inspect`（内省）と `pkgutil`（パッケージ走査）で、`timesfm` パッケージの公開API（関数・クラス）を列挙し、`pandas.DataFrame` に格納して表示します。\n",
    "\n",
    "- 収集対象：トップレベル + サブモジュール（importできる範囲）\n",
    "- import失敗（オプション依存など）はログとして別途確認可能\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python \"C:/moinfo/libs/timesfm/03_scripts/introspect_timesfm_features.py\" \\\n",
    "  --pkg timesfm \\\n",
    "  --out \"C:/moinfo/libs/timesfm/04_outputs/api/timesfm_public_api.json\" \\\n",
    "  --print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f7031",
   "metadata": {},
   "source": [
    "## TimesFM（timesfm）公開API（関数・クラス）を内省して DataFrame 化\n",
    "\n",
    "`inspect`（内省）と `pkgutil`（パッケージ走査）で、`timesfm` の公開API（関数・クラス）を抽出し、`pandas.DataFrame` に格納して表示します。\n",
    "\n",
    "- 収集対象：トップレベル + import可能なサブモジュール\n",
    "- import失敗（オプション依存など）は `modules_failed` に記録\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41969c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 共通モジュールを import できるようにする\n",
    "COMMON_DIR = r\"C:\\moinfo\\common\"\n",
    "if COMMON_DIR not in sys.path:\n",
    "    sys.path.insert(0, COMMON_DIR)\n",
    "\n",
    "from moinfo_introspect.public_api import collect_public_api, to_dataframe\n",
    "\n",
    "# 公開APIを収集\n",
    "data = collect_public_api(\"timesfm\", include_submodules=True)\n",
    "\n",
    "# DataFrame化\n",
    "df = to_dataframe(data)\n",
    "\n",
    "# 概要（メトリクス）\n",
    "summary_df = pd.DataFrame({\n",
    "    \"metric\": [\"api_items\", \"modules_ok\", \"modules_failed\"],\n",
    "    \"value\": [len(data[\"api\"]), len(data[\"modules_ok\"]), len(data[\"modules_failed\"])]\n",
    "})\n",
    "display(summary_df)\n",
    "\n",
    "# 種別内訳（class/function）\n",
    "display(df[\"kind\"].value_counts(dropna=False).to_frame(\"count\"))\n",
    "\n",
    "# テーブル本体（重いなら df.head(50) に変更）\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c3613f",
   "metadata": {},
   "source": [
    "## 生成された JSON を読み込み、DataFrame として可視化\n",
    "\n",
    "CLIで書き出した `timesfm_public_api.json` を読み込んで表示します（NotebookとCLIの結果一致確認用）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56833fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "json_path = r\"C:\\moinfo\\libs\\timesfm\\04_outputs\\api\\timesfm_public_api.json\"\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data_from_json = json.load(f)\n",
    "\n",
    "df2 = pd.DataFrame(data_from_json.get(\"api\", []))\n",
    "\n",
    "display(pd.DataFrame({\n",
    "    \"metric\": [\"api_items\", \"modules_ok\", \"modules_failed\"],\n",
    "    \"value\": [len(df2), len(data_from_json.get(\"modules_ok\", [])), len(data_from_json.get(\"modules_failed\", []))]\n",
    "}))\n",
    "display(df2[\"kind\"].value_counts(dropna=False).to_frame(\"count\"))\n",
    "display(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2724ce",
   "metadata": {},
   "source": [
    "# TimesFM 機能（公開API）イントロスペクト\n",
    "\n",
    "このノートは `timesfm` パッケージの関数・クラス・メソッドを機械的に列挙し、`pandas.DataFrame` に格納します。  \n",
    "副作用（import時に重い依存関係がロードされる等）があり得るため、必要なら「サブモジュール走査」をオフにします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2af0a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesfm module: timesfm\n",
      "timesfm file  : c:\\Users\\hashimoto.ryohei\\miniconda3\\envs\\kaiseki\\Lib\\site-packages\\timesfm\\__init__.py\n",
      "python        : 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT = Path(r\"C:\\moinfo\")\n",
    "SRC_DIR = ROOT / \"libs\" / \"timesfm\" / \"02_src\"\n",
    "\n",
    "# ローカルモジュール（moinfo_timesfm_ext）を import できるようにする\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# timesfm がインストールされているか確認（失敗したら pip/conda 側の問題）\n",
    "import importlib\n",
    "timesfm = importlib.import_module(\"timesfm\")\n",
    "\n",
    "print(\"timesfm module:\", timesfm.__name__)\n",
    "print(\"timesfm file  :\", getattr(timesfm, \"__file__\", \"n/a\"))\n",
    "print(\"python        :\", sys.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068df67f",
   "metadata": {},
   "source": [
    "## API 解析（関数・クラス・メソッド一覧）→ DataFrame 化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc59c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT = Path(r\"C:\\moinfo\")\n",
    "PKG_ROOT = ROOT / \"libs\" / \"timesfm\" / \"02_src\" / \"moinfo_timesfm_ext\"  # ★ここが重要\n",
    "\n",
    "if str(PKG_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PKG_ROOT))\n",
    "\n",
    "# 動作確認\n",
    "import moinfo_timesfm_ext\n",
    "print(\"moinfo_timesfm_ext:\", moinfo_timesfm_ext.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84931730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moinfo_timesfm_ext.moinfo_timesfm_ext.introspect_timesfm import collect_public_api, save_api_df\n",
    "\n",
    "df = collect_public_api(\n",
    "    package_name=\"timesfm\",\n",
    "    include_submodules=True,\n",
    "    include_private=False,\n",
    "    include_class_members=True,\n",
    "    max_doc_chars=250,\n",
    ")\n",
    "\n",
    "df.to_csv(r\"C:\\moinfo\\libs\\timesfm\\04_outputs\\tables\\timesfm_public_api_from_ext.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaac560",
   "metadata": {},
   "source": [
    "## TimesFM 公開APIの概要分析・分類・可視化\n",
    "\n",
    "- 種別（class/function/method/attribute/import_error）の分布\n",
    "- モジュール階層ごとの規模（どこに機能が集中しているか）\n",
    "- キーワードベースの機能分類（forecast / config / torch / util など）\n",
    "- ヒートマップで「種別×分類」の密度を見る\n",
    "- （任意）docstring を TF-IDF + k-means でクラスタリングして特徴語を抽出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任意：doc_summary を TF-IDF + k-means でクラスタリング\n",
    "# 目的：ルール分類では拾いきれない「自然な機能グループ」を見つける\n",
    "\n",
    "try:\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    texts = df2[\"doc_summary\"].fillna(\"\").astype(str)\n",
    "    # 空文は落とす（クラスタリングのノイズになる）\n",
    "    mask = texts.str.len() > 20\n",
    "    texts2 = texts[mask]\n",
    "    df_text = df2.loc[mask].copy()\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        stop_words=\"english\",\n",
    "        max_features=5000,\n",
    "        ngram_range=(1, 2),\n",
    "    )\n",
    "    X = vectorizer.fit_transform(texts2)\n",
    "\n",
    "    k = 8  # ざっくり。増やすと細かく割れる\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=0)\n",
    "    labels = km.fit_predict(X)\n",
    "    df_text[\"cluster\"] = labels\n",
    "\n",
    "    # クラスタごとの代表語（上位）\n",
    "    terms = np.array(vectorizer.get_feature_names_out())\n",
    "    top_words = []\n",
    "    for i in range(k):\n",
    "        center = km.cluster_centers_[i]\n",
    "        top_idx = center.argsort()[::-1][:12]\n",
    "        top_words.append(\", \".join(terms[top_idx]))\n",
    "\n",
    "    cluster_sizes = df_text[\"cluster\"].value_counts().sort_index()\n",
    "    summary = pd.DataFrame({\n",
    "        \"cluster\": range(k),\n",
    "        \"size\": [cluster_sizes.get(i, 0) for i in range(k)],\n",
    "        \"top_terms\": top_words,\n",
    "    }).sort_values(\"size\", ascending=False)\n",
    "\n",
    "    display(summary)\n",
    "\n",
    "    # 可視化：クラスタサイズ\n",
    "    plt.figure()\n",
    "    plt.bar(summary[\"cluster\"].astype(str), summary[\"size\"])\n",
    "    plt.title(\"Docstring clusters (k-means) sizes\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / \"timesfm_api_doc_clusters_sizes.png\", dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "    # 保存\n",
    "    summary.to_csv(OUT_TBL / \"timesfm_api_doc_clusters_summary.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    df_text.to_csv(OUT_TBL / \"timesfm_api_with_doc_clusters.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(\"Saved cluster outputs to:\", OUT_TBL)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Clustering skipped (scikit-learn not available or other error):\", repr(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c441cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# 1) kind 分布（class/method/function...）\n",
    "kind_counts = df2[\"kind\"].value_counts().reset_index()\n",
    "kind_counts.columns = [\"kind\", \"count\"]\n",
    "\n",
    "fig = px.bar(kind_counts, x=\"kind\", y=\"count\", title=\"TimesFM API: kind distribution\")\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()\n",
    "fig.write_html(str(OUT_FIG / \"timesfm_kind_distribution.html\"))\n",
    "\n",
    "# 2) category 分布（ルール分類）\n",
    "cat_counts = df2[\"category\"].value_counts().reset_index()\n",
    "cat_counts.columns = [\"category\", \"count\"]\n",
    "\n",
    "fig = px.bar(cat_counts, x=\"category\", y=\"count\", title=\"TimesFM API: category distribution (rule-based)\")\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()\n",
    "fig.write_html(str(OUT_FIG / \"timesfm_category_distribution.html\"))\n",
    "\n",
    "# 3) 上位モジュール（どこに機能が集中してる？）\n",
    "top_modules = (\n",
    "    df2.groupby(\"module_l2\")\n",
    "       .size()\n",
    "       .sort_values(ascending=False)\n",
    "       .head(25)\n",
    "       .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "fig = px.bar(top_modules[::-1], x=\"count\", y=\"module_l2\", orientation=\"h\",\n",
    "             title=\"Top modules (level2) by API surface\")\n",
    "fig.show()\n",
    "fig.write_html(str(OUT_FIG / \"timesfm_top_modules_l2.html\"))\n",
    "\n",
    "# 4) ヒートマップ：category × kind\n",
    "pivot = df2.pivot_table(index=\"category\", columns=\"kind\", values=\"qualname\", aggfunc=\"count\", fill_value=0)\n",
    "pivot = pivot.loc[pivot.sum(axis=1).sort_values(ascending=False).index, :]  # 行を多い順\n",
    "\n",
    "fig = px.imshow(\n",
    "    pivot,\n",
    "    title=\"Heatmap: category × kind (counts)\",\n",
    "    labels=dict(x=\"kind\", y=\"category\", color=\"count\"),\n",
    "    aspect=\"auto\",\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html(str(OUT_FIG / \"timesfm_heatmap_category_kind.html\"))\n",
    "\n",
    "print(\"Saved HTML figures to:\", OUT_FIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0cc567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path(r\"C:\\moinfo\")\n",
    "OUT_TBL = ROOT / \"libs\" / \"timesfm\" / \"04_outputs\" / \"tables\"\n",
    "OUT_TBL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- どのDFに \"cluster\" が入っているか吸収（df_text があれば優先）---\n",
    "df_clustered = None\n",
    "if \"df_text\" in globals() and isinstance(df_text, pd.DataFrame) and \"cluster\" in df_text.columns:\n",
    "    df_clustered = df_text.copy()\n",
    "elif \"df2\" in globals() and isinstance(df2, pd.DataFrame) and \"cluster\" in df2.columns:\n",
    "    df_clustered = df2.copy()\n",
    "elif \"df\" in globals() and isinstance(df, pd.DataFrame) and \"cluster\" in df.columns:\n",
    "    df_clustered = df.copy()\n",
    "\n",
    "if df_clustered is None:\n",
    "    raise RuntimeError(\"cluster 列が見つかりません。先に TF-IDF+kmeans のセルを実行して df_text を作ってください。\")\n",
    "\n",
    "# --- summary（cluster/size/top_terms）がある前提 ---\n",
    "if \"summary\" not in globals():\n",
    "    raise RuntimeError(\"summary(DataFrame: cluster/size/top_terms) が見つかりません。先にクラスタ要約を作ってください。\")\n",
    "\n",
    "# --- top_terms からテーマ推定（“テーブルから取得”のため、top_terms依存で判定）---\n",
    "def infer_theme(top_terms: str) -> tuple[str, str]:\n",
    "    t = (top_terms or \"\").lower()\n",
    "\n",
    "    if re.search(r\"\\bcompile\\b|share_mem|torch\", t):\n",
    "        return (\"Torch統合・高速化\", \"モデルのコンパイル(compile)やTorch実行系（高速デコード等）\")\n",
    "    if re.search(r\"state_dict|hook\", t):\n",
    "        return (\"状態管理・フック\", \"重み(state_dict)の保存/読込、Hook(フック)で挙動を差し込む\")\n",
    "    if re.search(r\"yields|iterator|return iterator\", t):\n",
    "        return (\"探索・列挙\", \"モジュール/サブモジュール/パラメータをイテレータで列挙する\")\n",
    "    if re.search(r\"parameters|buffers\", t):\n",
    "        return (\"パラメータ・バッファ\", \"parameters/buffers の取得・操作（学習/推論の材料）\")\n",
    "    if re.search(r\"modifies|module place|in place\", t):\n",
    "        return (\"in-place変換\", \"dtype/device 変更など“その場で”モジュールを書き換える操作\")\n",
    "    if re.search(r\"target exists|exists|error\", t):\n",
    "        return (\"検証・例外\", \"存在チェックやエラー処理（主にユーティリティ/検証）\")\n",
    "    if re.search(r\"evaluation mode|evaluation|mode\", t):\n",
    "        return (\"モード切替\", \"train/eval など推論モード/学習モードの切り替え\")\n",
    "    if re.search(r\"child|accessed|using given|get_\", t):\n",
    "        return (\"階層アクセス\", \"子モジュール/特定パラメータへ名前でアクセス（get_submodule等）\")\n",
    "\n",
    "    return (\"その他\", \"雑多な補助機能\")\n",
    "\n",
    "# --- 各クラスタの代表API（qualname）を抽出 ---\n",
    "# 代表の選び方：doc_summaryが長い＝説明がありそう、さらに timesfm/forecast/compile を優先\n",
    "def pick_examples(g: pd.DataFrame, k: int = 6) -> pd.DataFrame:\n",
    "    g = g.copy()\n",
    "    txt = (g[\"qualname\"].fillna(\"\") + \" \" + g[\"doc_summary\"].fillna(\"\")).str.lower()\n",
    "    score = (\n",
    "        g[\"doc_summary\"].fillna(\"\").str.len()\n",
    "        + txt.str.contains(\"forecast\").astype(int) * 200\n",
    "        + txt.str.contains(\"compile\").astype(int) * 150\n",
    "        + txt.str.contains(\"timesfm\").astype(int) * 80\n",
    "    )\n",
    "    g[\"_score\"] = score\n",
    "    return g.sort_values(\"_score\", ascending=False).head(k)\n",
    "\n",
    "examples = (\n",
    "    df_clustered.groupby(\"cluster\", group_keys=False)\n",
    "    .apply(pick_examples, k=6)\n",
    "    .loc[:, [\"cluster\", \"qualname\", \"kind\", \"module\", \"doc_summary\"]]\n",
    ")\n",
    "\n",
    "# --- 概要テーブル作成 ---\n",
    "ov = summary.copy()\n",
    "ov[\"theme\"], ov[\"what_you_can_do\"] = zip(*ov[\"top_terms\"].apply(infer_theme))\n",
    "\n",
    "# 代表APIを文字列にまとめる\n",
    "ex_str = (\n",
    "    examples.assign(ex=lambda d: d[\"qualname\"] + \" [\" + d[\"kind\"].astype(str) + \"]\")\n",
    "    .groupby(\"cluster\")[\"ex\"]\n",
    "    .apply(lambda s: \"\\n\".join(s.tolist()))\n",
    "    .reset_index()\n",
    "    .rename(columns={\"ex\": \"representative_api\"})\n",
    ")\n",
    "\n",
    "overview = ov.merge(ex_str, on=\"cluster\", how=\"left\").sort_values(\"size\", ascending=False)\n",
    "\n",
    "display(overview)\n",
    "\n",
    "# 保存（フルパス）\n",
    "out_csv = OUT_TBL / \"timesfm_cluster_overview.csv\"\n",
    "overview.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"saved:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "ROOT = Path(r\"C:\\moinfo\")\n",
    "OUT_FIG = ROOT / \"libs\" / \"timesfm\" / \"04_outputs\" / \"figs\"\n",
    "OUT_FIG.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Mermaidで壊れやすい文字を軽くエスケープ\n",
    "def esc(s: str) -> str:\n",
    "    s = (s or \"\")\n",
    "    s = s.replace('\"', \"'\")\n",
    "    s = re.sub(r\"[\\r\\n]+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "lines = []\n",
    "lines.append(\"graph TD\")\n",
    "lines.append('  R[\"timesfm API\"]')\n",
    "\n",
    "# overview がある前提\n",
    "for _, r in overview.iterrows():\n",
    "    c = int(r[\"cluster\"])\n",
    "    theme = esc(r[\"theme\"])\n",
    "    size = int(r[\"size\"])\n",
    "    node_c = f\"C{c}\"\n",
    "    lines.append(f'  R --> {node_c}[\"C{c}: {theme}\\\\n(size={size})\"]')\n",
    "\n",
    "    reps = (r.get(\"representative_api\") or \"\").splitlines()\n",
    "    reps = reps[:6]  # 多すぎると見づらいので上限\n",
    "    for i, api in enumerate(reps, start=1):\n",
    "        api = esc(api)\n",
    "        node_a = f\"{node_c}_{i}\"\n",
    "        lines.append(f'  {node_c} --> {node_a}[\"{api}\"]')\n",
    "\n",
    "mermaid_code = \"\\n\".join(lines)\n",
    "\n",
    "# 1) Notebook上に表示（Mermaid対応ビューアがある環境ならそのまま描画される）\n",
    "display(Markdown(\"```mermaid\\n\" + mermaid_code + \"\\n```\"))\n",
    "\n",
    "# 2) ファイル保存（フルパス）\n",
    "out_mmd = OUT_FIG / \"timesfm_api_clusters.mmd\"\n",
    "out_md  = OUT_FIG / \"timesfm_api_clusters_mermaid.md\"\n",
    "out_mmd.write_text(mermaid_code, encoding=\"utf-8\")\n",
    "out_md.write_text(\"```mermaid\\n\" + mermaid_code + \"\\n```\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"saved:\", out_mmd)\n",
    "print(\"saved:\", out_md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c951fad",
   "metadata": {},
   "source": [
    "# 1. サンプルデータセットの作成\n",
    "TimesFMの機能検証を行うため、明確な**トレンド（傾向）**と**季節性（周期性）**を持つ人工的な時系列データを生成します。\n",
    "\n",
    "モデルのコンテキスト長（入力）と予測ホライゾン（出力）をカバーできる十分な長さのデータを、以下の仕様で作成します。\n",
    "\n",
    "* **データ構造**: Pandas DataFrame (ロング形式)\n",
    "    * `date`: 日時インデックス\n",
    "    * `unique_id`: 系列を識別するID（多変量/複数系列対応のため）\n",
    "    * `value`: 観測値\n",
    "* **データ内容**:\n",
    "    * `series_01`: サイン波 + 上昇トレンド（基本的な周期的変動）\n",
    "    * `series_02`: コサイン波 + 緩やかなトレンド（位相の異なる変動）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dda160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_synthetic_series(length=1000, start_date=\"2024-01-01\", freq=\"h\"):\n",
    "    \"\"\"\n",
    "    トレンド、季節性、ノイズを含む人工的な時系列データを生成する関数\n",
    "    \"\"\"\n",
    "    # 日時インデックスの作成\n",
    "    dates = pd.date_range(start=start_date, periods=length, freq=freq)\n",
    "    x = np.linspace(0, 8 * np.pi, length)\n",
    "\n",
    "    # 系列1: サイン波 + 強いトレンド\n",
    "    y1 = np.sin(x) + np.linspace(0, 5, length) + np.random.normal(0, 0.1, length)\n",
    "    df1 = pd.DataFrame({\n",
    "        \"unique_id\": \"series_01\",\n",
    "        \"date\": dates,\n",
    "        \"value\": y1\n",
    "    })\n",
    "\n",
    "    # 系列2: コサイン波 + 弱いトレンド + 異なるノイズ\n",
    "    y2 = np.cos(x) + np.linspace(0, 2, length) + np.random.normal(0, 0.15, length)\n",
    "    df2 = pd.DataFrame({\n",
    "        \"unique_id\": \"series_02\",\n",
    "        \"date\": dates,\n",
    "        \"value\": y2\n",
    "    })\n",
    "\n",
    "    # 結合してロング形式へ\n",
    "    df_combined = pd.concat([df1, df2], ignore_index=True)\n",
    "    return df_combined\n",
    "\n",
    "# データ生成（TimesFMのデフォルトコンテキスト長 512 + 予測 128 をカバーできるサイズ）\n",
    "DATA_LENGTH = 1024\n",
    "df_sample = generate_synthetic_series(length=DATA_LENGTH)\n",
    "\n",
    "# データの確認\n",
    "print(f\"Data Shape: {df_sample.shape}\")\n",
    "display(df_sample.head())\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(12, 5))\n",
    "for uid, group in df_sample.groupby(\"unique_id\"):\n",
    "    plt.plot(group[\"date\"], group[\"value\"], label=uid, alpha=0.8)\n",
    "    \n",
    "plt.title(\"Synthetic Time Series Data for TimesFM Testing\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49212629",
   "metadata": {},
   "source": [
    "# 2. モデルのロード (修正版)\n",
    "\n",
    "`timesfm` ライブラリの仕様に合わせて、クラス名を `TimesFm` (mは小文字) に修正し、パラメータを `TimesFmHparams` 経由で設定します。\n",
    "\n",
    "**主な修正点:**\n",
    "1. クラス名: `TimesFM` -> `TimesFm`\n",
    "2. パラメータ指定: `hparams` 引数に `TimesFmHparams` オブジェクトを渡す形式に変更\n",
    "3. チェックポイント指定: `checkpoint` 引数に `TimesFmCheckpoint` オブジェクトを渡す形式に変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timesfm\n",
    "import numpy as np\n",
    "\n",
    "# 1. 予測設定 (ForecastConfig) の定義\n",
    "# 実際の入力長や予測したい期間に合わせて設定します\n",
    "forecast_config = timesfm.configs.ForecastConfig(\n",
    "    max_context=512,       # 入力系列の最大長\n",
    "    max_horizon=128,       # 予測期間の最大長\n",
    "    per_core_batch_size=1  # 1回の推論で処理するバッチサイズ\n",
    ")\n",
    "\n",
    "# 2. モデルのコンパイル (必須手順)\n",
    "print(\"Compiling model (this may take a few seconds)...\")\n",
    "tfm.compile(forecast_config)\n",
    "print(\"Model compiled successfully.\")\n",
    "\n",
    "# 3. 動作確認: ダミーデータによる予測\n",
    "# サイン波のダミーデータを作成 (長さ512)\n",
    "dummy_input = [np.sin(np.linspace(0, 20, 512))]\n",
    "\n",
    "# 予測実行\n",
    "# 戻り値: (点予測の結果, その他の情報) のタプル\n",
    "forecast_result = tfm.forecast(horizon=128, inputs=dummy_input)\n",
    "\n",
    "# 結果の確認\n",
    "# forecast_result[0] が予測値のメイン配列です\n",
    "print(f\"Forecast result type: {type(forecast_result)}\")\n",
    "print(f\"Point forecast shape: {forecast_result[0].shape}\")  # (Batch, Horizon) -> (1, 128) expected\n",
    "\n",
    "# 簡易プロット (オプション)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(512), dummy_input[0], label=\"History\")\n",
    "plt.plot(np.arange(512, 512+128), forecast_result[0][0], label=\"Forecast\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a670879",
   "metadata": {},
   "source": [
    "# 2-1. モデルロード方法の比較検証\n",
    "\n",
    "ご要望の通り、以下の2つのロード方法を両方試して検証します。\n",
    "\n",
    "1.  **`from_pretrained()`**: Hugging Face Hub からモデル定義と重みを一括でロードする（標準的方法）。\n",
    "2.  **`load_checkpoint()`**: ローカルに保存された重みファイルを、初期化済みのインスタンスに読み込む。\n",
    "\n",
    "**検証フロー:**\n",
    "1.  `from_pretrained` でモデル (A) をロード。\n",
    "2.  モデル (A) をローカルディレクトリに保存 (`save_pretrained`)。\n",
    "3.  新しい空のモデルインスタンス (B) を作成。\n",
    "4.  モデル (B) に `load_checkpoint` を使用して、保存したローカルの重みを読み込む。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e7e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timesfm\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# デバイス設定\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- 準備: 元モデルのロード ---\n",
    "print(\"=== Loading Source Model ===\")\n",
    "tfm_hub = timesfm.TimesFM_2p5_200M_torch.from_pretrained(\n",
    "    \"google/timesfm-2.5-200m-pytorch\",\n",
    "    backend=device\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# アプローチ1: 正攻法 (save_pretrained -> from_pretrained)\n",
    "# =========================================================\n",
    "print(\"\\n=== Approach 1: save_pretrained -> from_pretrained (Recommended) ===\")\n",
    "save_dir = \"./timesfm_hf_local\"\n",
    "tfm_hub.save_pretrained(save_dir)\n",
    "print(f\"Model saved to (HF format): {save_dir}\")\n",
    "\n",
    "# ローカルパスを指定してロード\n",
    "try:\n",
    "    tfm_local_hf = timesfm.TimesFM_2p5_200M_torch.from_pretrained(save_dir, backend=device)\n",
    "    print(\"Success: Loaded locally using from_pretrained()!\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed: {e}\")\n",
    "\n",
    "# =========================================================\n",
    "# アプローチ2: load_checkpoint の検証 (torch.save -> load_checkpoint)\n",
    "# =========================================================\n",
    "print(\"\\n=== Approach 2: torch.save -> load_checkpoint (Low-level) ===\")\n",
    "pt_file = \"./timesfm_state_dict.pt\"\n",
    "\n",
    "# 1. 生の state_dict を .pt ファイルとして保存\n",
    "# (Hugging Faceの形式ではなく、PyTorch標準の単一ファイル形式)\n",
    "torch.save(tfm_hub.model.state_dict(), pt_file)\n",
    "print(f\"Model weights saved to (PyTorch format): {pt_file}\")\n",
    "\n",
    "# 2. 空のモデルを作成して load_checkpoint で読み込む\n",
    "tfm_local_pt = timesfm.TimesFM_2p5_200M_torch(backend=device)\n",
    "\n",
    "try:\n",
    "    # load_checkpoint は内部で torch.load を呼んでいる可能性が高い\n",
    "    tfm_local_pt.load_checkpoint(pt_file)\n",
    "    print(\"Success: Loaded locally using load_checkpoint()!\")\n",
    "    \n",
    "    # コンパイル確認\n",
    "    print(\"Compiling loaded model...\")\n",
    "    tfm_local_pt.compile(timesfm.configs.ForecastConfig(max_context=64, max_horizon=32))\n",
    "    print(\"Compilation successful.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Failed to load checkpoint: {e}\")\n",
    "    # 失敗した場合、モデルの構造(キー名)を確認するデバッグ情報を出す\n",
    "    try:\n",
    "        loaded_dict = torch.load(pt_file)\n",
    "        print(\"Debug: Keys in saved file (top 5):\", list(loaded_dict.keys())[:5])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25067591",
   "metadata": {},
   "source": [
    "# 3. 予測設定 (Forecast Configuration)\n",
    "\n",
    "モデルのコンパイルを行う前に、予測時の挙動を制御する **`ForecastConfig`** オブジェクトを作成します。\n",
    "ここで設定するパラメータは、メモリ使用量や推論速度、予測の精度に影響します。\n",
    "\n",
    "主な設定項目:\n",
    "* `max_context`: モデルに入力する過去データの最大長（これより長い系列は切り詰められます）。\n",
    "* `max_horizon`: 一度に予測する未来の期間（予測ホライゾン）。\n",
    "* `per_core_batch_size`: 1回の推論処理でまとめて処理する系列の数（バッチサイズ）。\n",
    "* `normalize_inputs`: 入力データを正規化するかどうか（デフォルトは `False` ですが、データによっては有効）。\n",
    "* `use_continuous_quantile_head`: 分位点予測（不確実性の推定）を行う場合の設定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7110befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timesfm\n",
    "\n",
    "# 予測設定の定義\n",
    "# API定義に基づき、timesfm.configs.ForecastConfig を使用します\n",
    "forecast_config = timesfm.configs.ForecastConfig(\n",
    "    max_context=512,       # 入力コンテキスト長 (例: 過去512ステップ)\n",
    "    max_horizon=128,       # 予測ホライゾン (例: 未来128ステップ)\n",
    "    per_core_batch_size=32,# バッチサイズ (GPUメモリに応じて調整)\n",
    "    \n",
    "    # その他のオプション設定 (必要に応じて有効化)\n",
    "    normalize_inputs=True, # 入力系列の正規化を行うか\n",
    "    # quantiles=[0.1, 0.5, 0.9] # 分位点予測が必要な場合 (モデルの対応状況による)\n",
    ")\n",
    "\n",
    "# 設定内容の確認\n",
    "print(\"Forecast Config created:\")\n",
    "print(f\"  Max Context: {forecast_config.max_context}\")\n",
    "print(f\"  Max Horizon: {forecast_config.max_horizon}\")\n",
    "print(f\"  Batch Size : {forecast_config.per_core_batch_size}\")\n",
    "print(f\"  Normalize  : {forecast_config.normalize_inputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020722ce",
   "metadata": {},
   "source": [
    "# 3-1. ForecastConfig 引数の網羅的確認\n",
    "\n",
    "`ForecastConfig` で設定可能なすべての引数を確認します。\n",
    "解析結果およびライブラリの仕様に基づく設定項目は以下の通りです。\n",
    "\n",
    "| 引数名 | 型 | デフォルト値 | 概要 (推定) |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **`max_context`** | `int` | `0` (必須) | 入力系列の最大長。これを超える過去データは切り捨てられます。 |\n",
    "| **`max_horizon`** | `int` | `0` (必須) | 予測する未来の期間（予測ホライゾン）の最大長。 |\n",
    "| **`per_core_batch_size`** | `int` | `1` | 1回の推論ステップで処理する系列数（バッチサイズ）。 |\n",
    "| **`normalize_inputs`** | `bool` | `False` | 入力系列をモデルに入力する前に正規化（平均0、分散1など）するかどうか。 |\n",
    "| **`window_size`** | `int` | `0` | (高度な設定) 特定のウィンドウ処理を行う場合のサイズ。 |\n",
    "| **`use_continuous_quantile_head`** | `bool` | `False` | 連続的な分位点予測ヘッドを使用するかどうか（不確実性予測用）。 |\n",
    "| **`force_flip_invariance`** | `bool` | `True` | 上下反転に対する不変性を強制するかどうか。 |\n",
    "| **`infer_is_positive`** | `bool` | `True` | 値が正であることを推論時に考慮するかどうか。 |\n",
    "| **`fix_quantile_crossing`** | `bool` | `False` | 分位点同士の交差（矛盾）を修正するかどうか。 |\n",
    "| **`return_backcast`** | `bool` | `False` | 予測だけでなく、入力期間の適合値（バックキャスト）も返すかどうか。 |\n",
    "\n",
    "以下のコードで、実際のライブラリ定義からドキュメントとシグネチャを出力して確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timesfm\n",
    "import inspect\n",
    "\n",
    "# ForecastConfig クラスのシグネチャ（引数定義）を取得して表示\n",
    "print(\"--- ForecastConfig Signature ---\")\n",
    "sig = inspect.signature(timesfm.configs.ForecastConfig)\n",
    "for name, param in sig.parameters.items():\n",
    "    print(f\"{name}: {param.annotation} = {param.default}\")\n",
    "\n",
    "print(\"\\n--- Docstring ---\")\n",
    "print(timesfm.configs.ForecastConfig.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50963234",
   "metadata": {},
   "source": [
    "# 3-2. 設定パラメータの一覧化と網羅的検証\n",
    "\n",
    "`ForecastConfig` に設定可能なすべての引数をカラム（列）として持ち、検証したい値を格納した一覧表（DataFrame）を作成します。\n",
    "この表データを基に、実際に `ForecastConfig` オブジェクトを生成し、すべての値が正しく反映されるか検証します。\n",
    "\n",
    "**検証パターン:**\n",
    "1. **Case 0 (Standard)**: 一般的な推奨設定（正規化ON、非負制約ONなど）。\n",
    "2. **Case 1 (Experimental)**: すべてのオプション機能を有効化または変更した設定（分位点ヘッド使用、バックキャスト取得など）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e03d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import timesfm\n",
    "\n",
    "# 1. 検証用パラメータセットの定義\n",
    "# 引数名をキー、設定したい値のリストを値とする辞書を作成\n",
    "# Case 0: 実用的で標準的な設定\n",
    "# Case 1: オプション機能を網羅的に変更した設定\n",
    "validation_data = {\n",
    "    \"max_context\":                  [512,   1024],\n",
    "    \"max_horizon\":                  [128,   256],\n",
    "    \"per_core_batch_size\":          [32,    1],\n",
    "    \"normalize_inputs\":             [True,  False],\n",
    "    \"infer_is_positive\":            [True,  False],\n",
    "    \"force_flip_invariance\":        [True,  False],\n",
    "    \"use_continuous_quantile_head\": [False, True],\n",
    "    \"fix_quantile_crossing\":        [False, True],\n",
    "    \"return_backcast\":              [False, True],\n",
    "    \"window_size\":                  [0,     10]  # TODO機能だが引数としては存在\n",
    "}\n",
    "\n",
    "# 一覧表 (DataFrame) の作成\n",
    "df_configs = pd.DataFrame(validation_data)\n",
    "df_configs.index.name = \"Case\"\n",
    "\n",
    "print(\"--- ForecastConfig 検証用パラメータ一覧表 ---\")\n",
    "display(df_configs)\n",
    "\n",
    "# 2. 網羅的な検証実行\n",
    "print(\"\\n--- 設定反映の検証結果 ---\")\n",
    "\n",
    "generated_configs = []\n",
    "\n",
    "for idx, row in df_configs.iterrows():\n",
    "    # DataFrameの行を辞書に変換\n",
    "    params = row.to_dict()\n",
    "    \n",
    "    # 型の修正 (PandasはIntをFloatにすることがあるため、明示的にintへキャスト)\n",
    "    int_fields = [\"max_context\", \"max_horizon\", \"per_core_batch_size\", \"window_size\"]\n",
    "    for field in int_fields:\n",
    "        params[field] = int(params[field])\n",
    "    \n",
    "    try:\n",
    "        # Configオブジェクトの生成（引数展開 **params を使用）\n",
    "        config = timesfm.configs.ForecastConfig(**params)\n",
    "        \n",
    "        # 検証ロジック: 入力値とオブジェクトの属性値がすべて一致するか確認\n",
    "        mismatches = []\n",
    "        for key, expected_val in params.items():\n",
    "            actual_val = getattr(config, key)\n",
    "            if actual_val != expected_val:\n",
    "                mismatches.append(f\"{key}: expected {expected_val}, got {actual_val}\")\n",
    "        \n",
    "        if not mismatches:\n",
    "            print(f\"[Case {idx}] OK: 全てのパラメータが正常に設定されました。\")\n",
    "            generated_configs.append(config)\n",
    "        else:\n",
    "            print(f\"[Case {idx}] FAILED: パラメータの不一致があります -> {mismatches}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[Case {idx}] ERROR: 設定中にエラーが発生しました -> {e}\")\n",
    "\n",
    "# 最後に、検証に使用する設定（Case 0）を変数に保持\n",
    "forecast_config = generated_configs[0]\n",
    "print(f\"\\n最終的に採用する設定 (Case 0):\\n{forecast_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d36c8c",
   "metadata": {},
   "source": [
    "# 3-3. 予測設定クラスのアクセス方法検証\n",
    "\n",
    "TimesFMのAPIには、トップレベルの `timesfm.ForecastConfig` と、サブモジュールの `timesfm.configs.ForecastConfig` の2つのアクセス経路が存在します。\n",
    "両方を使用して設定オブジェクトを生成し、動作に違いがないか、およびこれらが同一のクラス定義を指しているかを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbdfdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timesfm\n",
    "\n",
    "# テスト用の設定値\n",
    "test_params = {\n",
    "    \"max_context\": 512,\n",
    "    \"max_horizon\": 128,\n",
    "    \"per_core_batch_size\": 16,\n",
    "    \"normalize_inputs\": True\n",
    "}\n",
    "\n",
    "print(\"=== 1. timesfm.ForecastConfig (Top-level) ===\")\n",
    "try:\n",
    "    config_v1 = timesfm.ForecastConfig(**test_params)\n",
    "    print(\"Success: Instance created via timesfm.ForecastConfig\")\n",
    "    print(f\"Object type: {type(config_v1)}\")\n",
    "    print(f\"Values: context={config_v1.max_context}, horizon={config_v1.max_horizon}\")\n",
    "except AttributeError:\n",
    "    print(\"Error: timesfm.ForecastConfig not found.\")\n",
    "\n",
    "print(\"\\n=== 2. timesfm.configs.ForecastConfig (Sub-module) ===\")\n",
    "try:\n",
    "    config_v2 = timesfm.configs.ForecastConfig(**test_params)\n",
    "    print(\"Success: Instance created via timesfm.configs.ForecastConfig\")\n",
    "    print(f\"Object type: {type(config_v2)}\")\n",
    "    print(f\"Values: context={config_v2.max_context}, horizon={config_v2.max_horizon}\")\n",
    "except AttributeError:\n",
    "    print(\"Error: timesfm.configs.ForecastConfig not found.\")\n",
    "\n",
    "print(\"\\n=== 3. Identity Verification ===\")\n",
    "# 両者が同じクラス定義を指しているか確認\n",
    "try:\n",
    "    is_same_class = timesfm.ForecastConfig is timesfm.configs.ForecastConfig\n",
    "    print(f\"Are they the same class definition? : {is_same_class}\")\n",
    "    \n",
    "    # データの内容が一致するか確認 (属性レベル)\n",
    "    if 'config_v1' in locals() and 'config_v2' in locals():\n",
    "        # __dict__ を比較して属性が全て同じかチェック\n",
    "        attrs_match = config_v1.__dict__ == config_v2.__dict__\n",
    "        print(f\"Do the instances have identical attributes? : {attrs_match}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Comparison failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5c084b",
   "metadata": {},
   "source": [
    "# 3-4. ForecastConfig クラス定義と引数の完全一致検証\n",
    "\n",
    "`timesfm.ForecastConfig` と `timesfm.configs.ForecastConfig` が、エイリアス（同一のクラス）であるか、あるいは異なる定義であるかを検証します。\n",
    "特に「設定できる引数」に差異がないか、`inspect` モジュールを使ってシグネチャレベルで比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3af6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timesfm\n",
    "import inspect\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=== ForecastConfig Class Verification ===\\n\")\n",
    "\n",
    "# 1. クラスオブジェクトの取得\n",
    "try:\n",
    "    cls_top = timesfm.ForecastConfig\n",
    "    print(\"Found: timesfm.ForecastConfig\")\n",
    "except AttributeError:\n",
    "    cls_top = None\n",
    "    print(\"Not Found: timesfm.ForecastConfig\")\n",
    "\n",
    "try:\n",
    "    cls_sub = timesfm.configs.ForecastConfig\n",
    "    print(\"Found: timesfm.configs.ForecastConfig\")\n",
    "except AttributeError:\n",
    "    cls_sub = None\n",
    "    print(\"Not Found: timesfm.configs.ForecastConfig\")\n",
    "\n",
    "# 2. 同一クラスかの判定 (Identity Check)\n",
    "if cls_top and cls_sub:\n",
    "    is_same = cls_top is cls_sub\n",
    "    print(f\"\\n[Identity Check] Are they the same object? : {is_same}\")\n",
    "    if is_same:\n",
    "        print(\">> 結論: 完全に同一のクラスです（トップレベルはエイリアスです）。引数に違いはありません。\")\n",
    "    else:\n",
    "        print(\">> 結論: 異なるクラスオブジェクトです。詳細な引数比較を行います。\")\n",
    "\n",
    "# 3. 引数(シグネチャ)の厳密比較\n",
    "if cls_top and cls_sub:\n",
    "    sig_top = inspect.signature(cls_top)\n",
    "    sig_sub = inspect.signature(cls_sub)\n",
    "    \n",
    "    print(f\"\\n[Signature Check]\")\n",
    "    print(f\"Top-level args: {len(sig_top.parameters)} items\")\n",
    "    print(f\"Sub-module args: {len(sig_sub.parameters)} items\")\n",
    "    \n",
    "    # 比較用データフレーム作成\n",
    "    params_top = {k: str(v) for k, v in sig_top.parameters.items()}\n",
    "    params_sub = {k: str(v) for k, v in sig_sub.parameters.items()}\n",
    "    \n",
    "    # 全ての引数キーを統合\n",
    "    all_keys = sorted(set(params_top.keys()) | set(params_sub.keys()))\n",
    "    \n",
    "    comparison_data = []\n",
    "    for key in all_keys:\n",
    "        val_top = params_top.get(key, \"(Not Present)\")\n",
    "        val_sub = params_sub.get(key, \"(Not Present)\")\n",
    "        match = (val_top == val_sub)\n",
    "        comparison_data.append([key, val_top, val_sub, match])\n",
    "        \n",
    "    df_comparison = pd.DataFrame(comparison_data, columns=[\"Argument\", \"timesfm.ForecastConfig\", \"timesfm.configs.ForecastConfig\", \"Match\"])\n",
    "    \n",
    "    # 不一致がある場合のみ表示、または全一致を表示\n",
    "    if df_comparison[\"Match\"].all():\n",
    "        print(\">> 引数定義は完全に一致しています。\")\n",
    "    else:\n",
    "        print(\">> 差異が見つかりました：\")\n",
    "        display(df_comparison[~df_comparison[\"Match\"]])\n",
    "\n",
    "    # 全体一覧（確認用）\n",
    "    print(\"\\n--- 引数一覧 ---\")\n",
    "    display(df_comparison)\n",
    "\n",
    "elif not cls_top:\n",
    "    print(\"\\n検証不可: timesfm.ForecastConfig が存在しません。timesfm.configs.ForecastConfig を使用してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b457c96",
   "metadata": {},
   "source": [
    "# 4. コンパイルと予測実行 (Compile & Forecast)\n",
    "\n",
    "検証済みの設定 (`forecast_config`) を使用して、以下のフローを実行します。\n",
    "\n",
    "1.  **コンパイル (`compile`)**: 設定に基づき、モデルの推論プロセスを最適化します（**必須**）。\n",
    "2.  **データ準備**: サンプル DataFrame (`df_sample`) を、モデルが受け付ける `List[numpy.ndarray]` 形式に変換します。\n",
    "3.  **予測 (`forecast`)**: コンパイルされたモデルで未来の値を予測します。\n",
    "4.  **結合・可視化**: 予測結果を元の DataFrame と結合し、グラフで確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed99d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. モデルのコンパイル (必須) ---\n",
    "# 前のステップで作成した推奨設定 (Case 0) を使用\n",
    "print(f\"Compiling model with config: {forecast_config} ...\")\n",
    "tfm.compile(forecast_config)\n",
    "print(\"Model compiled successfully.\")\n",
    "\n",
    "# --- 2. データ準備 (DataFrame -> List[np.array]) ---\n",
    "# TimesFM v2.5 の forecast メソッドはリスト形式の numpy 配列を受け取ります\n",
    "# unique_id ごとにデータを分割してリスト化\n",
    "input_data_map = {}\n",
    "input_arrays = []\n",
    "\n",
    "# 系列IDの順序を保持するためにリストを作成\n",
    "unique_ids = df_sample['unique_id'].unique()\n",
    "\n",
    "for uid in unique_ids:\n",
    "    # 各系列の値を抽出\n",
    "    series_values = df_sample[df_sample['unique_id'] == uid]['value'].values\n",
    "    input_arrays.append(series_values)\n",
    "    input_data_map[uid] = series_values\n",
    "\n",
    "print(f\"Prepared {len(input_arrays)} input series for forecasting.\")\n",
    "\n",
    "# --- 3. 予測実行 (Forecast) ---\n",
    "# horizon は config の max_horizon と同じか、それ以下である必要があります\n",
    "forecast_horizon = forecast_config.max_horizon\n",
    "print(f\"Forecasting next {forecast_horizon} steps...\")\n",
    "\n",
    "# 戻り値: (点予測[Batch, Horizon], その他情報)\n",
    "forecast_result = tfm.forecast(\n",
    "    inputs=input_arrays,\n",
    "    horizon=forecast_horizon\n",
    ")\n",
    "\n",
    "# 予測値の取得 (0番目の要素が点予測)\n",
    "point_forecasts = forecast_result[0]\n",
    "print(f\"Forecast shape: {point_forecasts.shape}\") # (2, 128) expected\n",
    "\n",
    "# --- 4. 結果の整理と可視化 ---\n",
    "# 予測結果をDataFrame化して可視化\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for i, uid in enumerate(unique_ids):\n",
    "    history = input_arrays[i]\n",
    "    forecast = point_forecasts[i]\n",
    "    \n",
    "    # 日時軸の作成 (簡易的に履歴の続きとして生成)\n",
    "    last_date = df_sample[df_sample['unique_id'] == uid]['date'].max()\n",
    "    freq = \"h\" # サンプルデータの頻度\n",
    "    future_dates = pd.date_range(start=last_date + pd.Timedelta(hours=1), periods=forecast_horizon, freq=freq)\n",
    "    \n",
    "    # 履歴のプロット (直近の一部のみ表示)\n",
    "    display_len = 200\n",
    "    plt.plot(\n",
    "        df_sample[df_sample['unique_id'] == uid]['date'].iloc[-display_len:], \n",
    "        history[-display_len:], \n",
    "        label=f\"{uid} (History)\", \n",
    "        linestyle=\"--\"\n",
    "    )\n",
    "    \n",
    "    # 予測のプロット\n",
    "    plt.plot(future_dates, forecast, label=f\"{uid} (Forecast)\", linewidth=2)\n",
    "\n",
    "plt.title(\"TimesFM Forecast Result\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba5797",
   "metadata": {},
   "source": [
    "# 5. 単変量予測の比較検証 (Univariate Forecasting)\n",
    "\n",
    "`forecast()` と `forecast_on_df()` の両方のアプローチを比較します。\n",
    "\n",
    "1.  **`forecast()`**:\n",
    "    * **概要**: NumPy配列のリストを入力とする基本API。\n",
    "    * **特徴**: 高速でオーバーヘッドが少ないが、日付やIDの管理は自分で行う必要がある。\n",
    "    * **現状**: `TimesFM_2p5_200M_torch` クラス標準実装。\n",
    "\n",
    "2.  **`forecast_on_df()` (再現実装)**:\n",
    "    * **概要**: Pandas DataFrame (Long形式) を直接受け取り、予測結果もDataFrameで返す。\n",
    "    * **特徴**: 前処理・後処理（日付生成、ID結合）を自動化し、分析フローに組み込みやすい。\n",
    "    * **現状**: v2.5のモデルクラスには直接実装されていないため、ヘルパー関数として定義して使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d12eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- A. 標準機能: forecast() の実行 ---\n",
    "print(\"=== A. Testing forecast() (Array Input) ===\")\n",
    "\n",
    "# 1. データの準備 (DataFrame -> List[np.ndarray])\n",
    "# 各系列の値をリストに格納\n",
    "inputs_list = []\n",
    "ids = df_sample['unique_id'].unique()\n",
    "for uid in ids:\n",
    "    series = df_sample[df_sample['unique_id'] == uid]['value'].values\n",
    "    inputs_list.append(series)\n",
    "\n",
    "# 2. 予測実行\n",
    "# コンパイル済みの設定 (max_horizon=128) を使用\n",
    "print(f\"Input type: List of {len(inputs_list)} arrays\")\n",
    "raw_forecast = tfm.forecast(inputs=inputs_list, horizon=128)\n",
    "\n",
    "# 結果は (PointForecast, ...) のタプル\n",
    "point_forecast_array = raw_forecast[0]\n",
    "print(f\"Output shape: {point_forecast_array.shape}\")\n",
    "print(\"forecast() test passed.\\n\")\n",
    "\n",
    "\n",
    "# --- B. 拡張機能: forecast_on_df() の再現と実行 ---\n",
    "print(\"=== B. Testing forecast_on_df() (DataFrame Input) ===\")\n",
    "\n",
    "def forecast_on_df(model, df, unique_id_col=\"unique_id\", value_col=\"value\", date_col=\"date\", freq=\"h\"):\n",
    "    \"\"\"\n",
    "    TimesFM v2.5向けに forecast_on_df の機能を再現するラッパー関数\n",
    "    \"\"\"\n",
    "    # 1. 前処理: データフレームから配列リストへ変換\n",
    "    unique_ids = df[unique_id_col].unique()\n",
    "    inputs = []\n",
    "    last_dates = []\n",
    "    \n",
    "    for uid in unique_ids:\n",
    "        sub_df = df[df[unique_id_col] == uid].sort_values(date_col)\n",
    "        inputs.append(sub_df[value_col].values)\n",
    "        last_dates.append(sub_df[date_col].max())\n",
    "    \n",
    "    # 2. 推論実行\n",
    "    # configから予測期間を取得\n",
    "    horizon = model.forecast_config.max_horizon\n",
    "    forecast_tuple = model.forecast(inputs=inputs, horizon=horizon)\n",
    "    forecast_values = forecast_tuple[0] # (N, Horizon)\n",
    "    \n",
    "    # 3. 後処理: 結果をDataFrame形式に復元\n",
    "    results = []\n",
    "    for idx, uid in enumerate(unique_ids):\n",
    "        # 未来の日付インデックスを作成\n",
    "        start_date = last_dates[idx] + pd.Timedelta(1, unit=freq)\n",
    "        future_dates = pd.date_range(start=start_date, periods=horizon, freq=freq)\n",
    "        \n",
    "        # 結果用DF作成\n",
    "        res_df = pd.DataFrame({\n",
    "            unique_id_col: uid,\n",
    "            date_col: future_dates,\n",
    "            \"timesfm_forecast\": forecast_values[idx]\n",
    "        })\n",
    "        results.append(res_df)\n",
    "        \n",
    "    return pd.concat(results, ignore_index=True)\n",
    "\n",
    "# 実行テスト\n",
    "df_forecast_result = forecast_on_df(\n",
    "    model=tfm, \n",
    "    df=df_sample, \n",
    "    unique_id_col=\"unique_id\", \n",
    "    value_col=\"value\", \n",
    "    date_col=\"date\",\n",
    "    freq=\"h\"\n",
    ")\n",
    "\n",
    "# 結果確認\n",
    "print(\"Forecast DataFrame Head:\")\n",
    "display(df_forecast_result.head())\n",
    "\n",
    "# 可視化 (forecast_on_df の結果を使用)\n",
    "plt.figure(figsize=(12, 5))\n",
    "for uid in ids:\n",
    "    # 実績\n",
    "    history = df_sample[df_sample['unique_id'] == uid]\n",
    "    plt.plot(history['date'].iloc[-100:], history['value'].iloc[-100:], label=f\"{uid} History\", linestyle=\"--\", alpha=0.7)\n",
    "    \n",
    "    # 予測\n",
    "    pred = df_forecast_result[df_forecast_result['unique_id'] == uid]\n",
    "    plt.plot(pred['date'], pred['timesfm_forecast'], label=f\"{uid} Forecast\", linewidth=2)\n",
    "\n",
    "plt.title(\"Forecast Result using 'forecast_on_df' wrapper\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222de55",
   "metadata": {},
   "source": [
    "# 6. 外部変数付き予測 (再修正版: Backcast有効化)\n",
    "このノートでは `forecast_with_covariates()` を使って、以下4種類の共変量（Covariates）を与えた予測を試す。\n",
    "\n",
    "- 動的・数値（dynamic numerical）：例）プロモ有無、気温など（時刻ごとに変化）\n",
    "- 動的・カテゴリ（dynamic categorical）：例）曜日、祝日フラグなど（時刻ごとに変化）\n",
    "- 静的・数値（static numerical）：例）店舗面積、平均単価など（系列ごとに固定）\n",
    "- 静的・カテゴリ（static categorical）：例）国、地域、店舗IDなど（系列ごとに固定）\n",
    "\n",
    "重要：動的共変量は「過去(context) + 未来(horizon)」の長さが必要。\n",
    "つまり `len(cov[t]) == context_len + horizon_len`。\n",
    "\n",
    "返り値：\n",
    "- `cov_forecast`：既定では `\"xreg + timesfm\"`（XRegで補正したTimesFM予測）\n",
    "- `ols_forecast`：`\"xreg\"` 成分のみ（回帰だけの予測、比較用）\n",
    "\n",
    "※ TimesFM 2.5 は XReg による共変量サポートが復活している（`.[xreg]` が必要）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca5ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(\"sys.executable =\", sys.executable)\n",
    "\n",
    "try:\n",
    "    import jax, jaxlib\n",
    "    print(\"jax =\", jax.__version__)\n",
    "    print(\"jaxlib =\", jaxlib.__version__)\n",
    "except Exception as e:\n",
    "    print(\"JAX import failed:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall -y jax jaxlib\n",
    "%pip install -U pip\n",
    "%pip install -U jax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ed0549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax, jaxlib\n",
    "print(jax.__version__, jaxlib.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e96257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import inspect\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import timesfm\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# --- 1) 設定 ---\n",
    "BATCH_SIZE  = 8\n",
    "CONTEXT_LEN = 512\n",
    "HORIZON_LEN = 128\n",
    "TOTAL_LEN   = CONTEXT_LEN + HORIZON_LEN\n",
    "\n",
    "MODEL_LOCAL_DIR = r\"C:\\moinfo\\timesfm_v2.5_local\"\n",
    "MODEL_HF_ID     = \"google/timesfm-2.5-200m-pytorch\"\n",
    "\n",
    "# --- 2) モデル読込（ローカル -> HF の順で試す） ---\n",
    "def load_timesfm_2p5():\n",
    "    try:\n",
    "        if os.path.isdir(MODEL_LOCAL_DIR):\n",
    "            print(f\"Loading model from local dir: {MODEL_LOCAL_DIR}\")\n",
    "            return timesfm.TimesFM_2p5_200M_torch.from_pretrained(MODEL_LOCAL_DIR)\n",
    "    except Exception as e:\n",
    "        print(\"Local load failed, fallback to HF:\", repr(e))\n",
    "\n",
    "    print(f\"Loading model from HF: {MODEL_HF_ID}\")\n",
    "    return timesfm.TimesFM_2p5_200M_torch.from_pretrained(MODEL_HF_ID)\n",
    "\n",
    "model = load_timesfm_2p5()\n",
    "\n",
    "# ★重要：XRegを使うなら return_backcast=True が必須\n",
    "bench_cfg = timesfm.ForecastConfig(\n",
    "    max_context=CONTEXT_LEN,\n",
    "    max_horizon=HORIZON_LEN,\n",
    "    per_core_batch_size=BATCH_SIZE,\n",
    "    normalize_inputs=True,\n",
    "    return_backcast=True,   # ← これを追加！\n",
    ")\n",
    "\n",
    "print(\"Compiling with return_backcast=True ...\")\n",
    "model.compile(bench_cfg)\n",
    "\n",
    "# --- 3) ダミー入力（ターゲット系列） ---\n",
    "inputs = [np.sin(np.linspace(0, 30, CONTEXT_LEN)).astype(np.float32) for _ in range(BATCH_SIZE)]\n",
    "\n",
    "# --- 4) 共変量を作る（最小例） ---\n",
    "t = np.arange(TOTAL_LEN, dtype=np.int32)\n",
    "\n",
    "dynamic_numerical_covariates = {\n",
    "    \"promo\": [(np.random.rand(TOTAL_LEN) < 0.1).astype(np.float32) for _ in range(BATCH_SIZE)]\n",
    "}\n",
    "\n",
    "dynamic_categorical_covariates = {\n",
    "    \"week_day\": [((t + np.random.randint(0, 7)) % 7).astype(np.int32) for _ in range(BATCH_SIZE)]\n",
    "}\n",
    "\n",
    "static_numerical_covariates = {\n",
    "    \"store_size\": [float(np.random.uniform(0.5, 2.0)) for _ in range(BATCH_SIZE)]\n",
    "}\n",
    "\n",
    "static_categorical_covariates = {\n",
    "    \"region\": [random.choice([\"JP\", \"US\", \"EU\"]) for _ in range(BATCH_SIZE)]\n",
    "}\n",
    "\n",
    "# --- 5) 互換ラッパ（引数差を吸収） ---\n",
    "def forecast_with_covariates_compat(\n",
    "    model,\n",
    "    inputs,\n",
    "    horizon,\n",
    "    dynamic_numerical_covariates=None,\n",
    "    dynamic_categorical_covariates=None,\n",
    "    static_numerical_covariates=None,\n",
    "    static_categorical_covariates=None,\n",
    "    xreg_mode=\"xreg + timesfm\",\n",
    "    ridge=0.0,\n",
    "    force_on_cpu=False,\n",
    "    normalize_xreg_target_per_input=True,\n",
    "):\n",
    "    if not hasattr(model, \"forecast_with_covariates\"):\n",
    "        raise AttributeError(\"この model に forecast_with_covariates が見つかりません。timesfm を xreg 対応で入れているか確認してください。\")\n",
    "\n",
    "    fn = model.forecast_with_covariates\n",
    "    sig = inspect.signature(fn)\n",
    "    kwargs = dict(\n",
    "        inputs=inputs,\n",
    "        dynamic_numerical_covariates=dynamic_numerical_covariates or {},\n",
    "        dynamic_categorical_covariates=dynamic_categorical_covariates or {},\n",
    "        static_numerical_covariates=static_numerical_covariates or {},\n",
    "        static_categorical_covariates=static_categorical_covariates or {},\n",
    "        xreg_mode=xreg_mode,\n",
    "        ridge=ridge,\n",
    "        force_on_cpu=force_on_cpu,\n",
    "        normalize_xreg_target_per_input=normalize_xreg_target_per_input,\n",
    "    )\n",
    "\n",
    "    if \"horizon\" in sig.parameters:\n",
    "        kwargs[\"horizon\"] = horizon\n",
    "    if \"freq\" in sig.parameters:\n",
    "        kwargs[\"freq\"] = [0] * len(inputs)\n",
    "\n",
    "    return fn(**kwargs)\n",
    "\n",
    "# --- 6) TimesFM 単体の予測 ---\n",
    "try:\n",
    "    base_point, _ = model.forecast(horizon=HORIZON_LEN, inputs=inputs)\n",
    "except TypeError:\n",
    "    base_point, _ = model.forecast(inputs=inputs, freq=[0]*len(inputs))\n",
    "\n",
    "base_point = np.asarray(base_point)\n",
    "print(\"base_point shape:\", base_point.shape)\n",
    "\n",
    "# --- 7) 共変量付き予測（XReg）---\n",
    "cov_forecast, ols_forecast = forecast_with_covariates_compat(\n",
    "    model=model,\n",
    "    inputs=inputs,\n",
    "    horizon=HORIZON_LEN,\n",
    "    dynamic_numerical_covariates=dynamic_numerical_covariates,\n",
    "    dynamic_categorical_covariates=dynamic_categorical_covariates,\n",
    "    static_numerical_covariates=static_numerical_covariates,\n",
    "    static_categorical_covariates=static_categorical_covariates,\n",
    "    xreg_mode=\"xreg + timesfm\",\n",
    "    ridge=0.0,\n",
    "    force_on_cpu=False,\n",
    "    normalize_xreg_target_per_input=True,\n",
    ")\n",
    "\n",
    "cov_forecast = np.asarray(cov_forecast)\n",
    "ols_forecast = np.asarray(ols_forecast)\n",
    "\n",
    "print(\"cov_forecast shape:\", cov_forecast.shape)\n",
    "print(\"ols_forecast shape:\", ols_forecast.shape)\n",
    "\n",
    "# --- 8) 可視化（先頭系列だけ） ---\n",
    "\n",
    "base_point = np.asarray(base_point)\n",
    "cov_forecast = np.asarray(cov_forecast)\n",
    "ols_forecast = np.asarray(ols_forecast)\n",
    "\n",
    "# ★ 未来だけ取り出す（return_backcast=True のとき必須）\n",
    "base_future = base_point[:, -HORIZON_LEN:]   # shape: (B, 128)\n",
    "\n",
    "# OLS側は (B, 128, 10) なので、代表として中央値(0.5)っぽい列を選ぶ\n",
    "# どの列が中央値かは実装依存なので、まず真ん中を取る（10本→ index=5）\n",
    "ols_median = ols_forecast[:, :, ols_forecast.shape[-1] // 2]  # shape: (B, 128)\n",
    "\n",
    "x_ctx = np.arange(CONTEXT_LEN)\n",
    "x_fut = np.arange(CONTEXT_LEN, CONTEXT_LEN + HORIZON_LEN)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(x_ctx, inputs[0], label=\"input (context)\")\n",
    "plt.plot(x_fut, base_future[0], label=\"TimesFM (base, future only)\")\n",
    "plt.plot(x_fut, cov_forecast[0], label=\"XReg + TimesFM (cov_forecast)\")\n",
    "plt.plot(x_fut, ols_median[0], label=\"XReg only (ols median)\", linestyle=\"--\")\n",
    "plt.title(\"TimesFM forecast_with_covariates: base vs covariates\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "backcast_len = base_point.shape[1] - HORIZON_LEN\n",
    "base_backcast = base_point[:, :backcast_len]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(np.arange(CONTEXT_LEN), inputs[0], label=\"input (context)\")\n",
    "plt.plot(np.arange(CONTEXT_LEN - backcast_len, CONTEXT_LEN), base_backcast[0], label=\"TimesFM (backcast)\")\n",
    "plt.plot(np.arange(CONTEXT_LEN, CONTEXT_LEN + HORIZON_LEN), base_future[0], label=\"TimesFM (forecast)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602328b9",
   "metadata": {},
   "source": [
    "# 7. ベクトル抽出 (構造特定と自動フック)\n",
    "\n",
    "モデルの内部構造を表示し、特徴量抽出に最適なレイヤー（通常は最後のTransformerブロックや正規化層）を特定してフックします。\n",
    "\n",
    "**アプローチ:**\n",
    "1. `named_modules()` を走査し、モデルの階層構造をテキストで出力して確認します。\n",
    "2. 名前リストの中から、`layers` や `blocks` を含む最も深いインデックスを持つ層を自動検出し、ターゲットにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4733acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timesfm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. モデル構造の「レントゲン撮影」 ---\n",
    "print(\"=== Inspecting Model Internal Layers ===\")\n",
    "\n",
    "# モデル内の主要なモジュール名を表示 (深さ2まで)\n",
    "# これで layers, blocks, transformer などの名前を確認します\n",
    "found_layers = []\n",
    "for name, module in tfm.model.named_modules():\n",
    "    # 名前が空（自分自身）はスキップ\n",
    "    if not name: continue\n",
    "    \n",
    "    # 全て表示すると多すぎるので、主要なコンポーネントのみ記録\n",
    "    found_layers.append(name)\n",
    "    \n",
    "    # トップレベル付近のみ表示\n",
    "    if name.count('.') <= 1:\n",
    "        print(f\" - {name}: {module.__class__.__name__}\")\n",
    "\n",
    "print(f\"\\nTotal modules found: {len(found_layers)}\")\n",
    "\n",
    "# --- 2. ターゲット層の自動選定 ---\n",
    "# 「layers.数字」のようなパターンを探し、その最大番号（最終層）を特定します\n",
    "target_name = None\n",
    "max_layer_idx = -1\n",
    "\n",
    "for name in found_layers:\n",
    "    parts = name.split('.')\n",
    "    # \"layers.19\" や \"blocks.19\" のようなパターンを検出\n",
    "    for i, part in enumerate(parts):\n",
    "        if part.isdigit() and i > 0:\n",
    "            # 数字の前の部分がコンテナ名 (layers, blocks等)\n",
    "            container_name = parts[i-1]\n",
    "            idx = int(part)\n",
    "            \n",
    "            # コンテナ名が一般的かチェック\n",
    "            if container_name in ['layers', 'blocks', 'h', 'transformer']:\n",
    "                if idx > max_layer_idx:\n",
    "                    max_layer_idx = idx\n",
    "                    # この数字までのパスをターゲット候補とする\n",
    "                    target_name = \".\".join(parts[:i+1])\n",
    "\n",
    "# もし数字付きレイヤーが見つからない場合、output_layerやnormを探す\n",
    "if target_name is None:\n",
    "    for name in found_layers:\n",
    "        if 'output' in name or 'final_norm' in name or 'ln_f' in name:\n",
    "            target_name = name\n",
    "            break\n",
    "\n",
    "print(f\"\\nTarget Layer Auto-Selected: '{target_name}'\")\n",
    "\n",
    "# --- 3. 選択した層へのフックとベクトル抽出 ---\n",
    "if target_name:\n",
    "    # 名前から実際のモジュールオブジェクトを取得\n",
    "    target_module = dict(tfm.model.named_modules())[target_name]\n",
    "    \n",
    "    embeddings_storage = {}\n",
    "    \n",
    "    # 堅牢なフック関数 (再定義)\n",
    "    def robust_hook(name):\n",
    "        def hook(model, input, output):\n",
    "            # Tensorを探す\n",
    "            if isinstance(output, torch.Tensor):\n",
    "                tensor = output\n",
    "            elif isinstance(output, (tuple, list)):\n",
    "                tensor = output[0] if len(output) > 0 and isinstance(output[0], torch.Tensor) else None\n",
    "            else:\n",
    "                tensor = None\n",
    "                \n",
    "            if tensor is not None:\n",
    "                embeddings_storage[name] = tensor.detach().cpu().numpy()\n",
    "        return hook\n",
    "\n",
    "    # フック登録\n",
    "    handle = target_module.register_forward_hook(robust_hook('feature_embedding'))\n",
    "    print(f\"Hook registered on: {target_module.__class__.__name__}\")\n",
    "\n",
    "    # 予測実行\n",
    "    print(\"Running forecast to extract features...\")\n",
    "    try:\n",
    "        _ = tfm.forecast(inputs=input_data, horizon=128)\n",
    "    except Exception as e:\n",
    "        print(f\"Forecast warning: {e}\")\n",
    "\n",
    "    # フック解除\n",
    "    handle.remove()\n",
    "\n",
    "    # --- 4. 可視化 ---\n",
    "    if 'feature_embedding' in embeddings_storage:\n",
    "        emb = embeddings_storage['feature_embedding']\n",
    "        print(f\"\\nSuccess! Extracted Embedding Shape: {emb.shape}\")\n",
    "        \n",
    "        # ヒートマップ\n",
    "        feature_map = emb[0, :, :200].T\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.imshow(feature_map, aspect='auto', cmap='magma', origin='lower')\n",
    "        plt.colorbar(label='Activation')\n",
    "        plt.title(f\"TimesFM Feature Embeddings\\nLayer: {target_name}\")\n",
    "        plt.xlabel(\"Time Patch Index\")\n",
    "        plt.ylabel(\"Feature Dimension (First 200)\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Error: Failed to capture embeddings (Tensor not found in output).\")\n",
    "\n",
    "else:\n",
    "    print(\"Error: Could not automatically identify a target layer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba195f1",
   "metadata": {},
   "source": [
    "# 7-2. 特徴量のテーブル表示 (DataFrame)\n",
    "\n",
    "モデルの内部構造解析により、`stacked_xf` という名前でTransformerブロックが積み重なっていることが分かりました。\n",
    "最も抽象度の高い特徴量を持つ **`stacked_xf.19` (最終層)** をターゲットにして再度ベクトル抽出を行い、その数値を**テーブル（DataFrame）**として整形・表示します。\n",
    "\n",
    "* **行 (Index)**: 時系列のパッチ（時間ステップ）\n",
    "* **列 (Columns)**: 特徴量の次元（0 ~ 1279）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ec147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import timesfm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 1. ターゲット層 (stacked_xf.19) へのフック登録 ---\n",
    "target_layer_name = 'stacked_xf.19'  # 構造解析で見つかった最終Transformer層\n",
    "print(f\"=== Hooking into target: {target_layer_name} ===\")\n",
    "\n",
    "# モジュールの取得\n",
    "target_module = dict(tfm.model.named_modules())[target_layer_name]\n",
    "\n",
    "# データ格納用\n",
    "embeddings_storage = {}\n",
    "\n",
    "# 堅牢なフック関数\n",
    "def robust_hook(name):\n",
    "    def hook(model, input, output):\n",
    "        # Tensorを探す (Tupleの中に隠れている場合があるため)\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            tensor = output\n",
    "        elif isinstance(output, (tuple, list)):\n",
    "            tensor = output[0] if len(output) > 0 and isinstance(output[0], torch.Tensor) else None\n",
    "        else:\n",
    "            tensor = None\n",
    "            \n",
    "        if tensor is not None:\n",
    "            embeddings_storage[name] = tensor.detach().cpu().numpy()\n",
    "    return hook\n",
    "\n",
    "# フック登録\n",
    "handle = target_module.register_forward_hook(robust_hook('deep_features'))\n",
    "\n",
    "# --- 2. 予測実行 (特徴量抽出) ---\n",
    "print(\"Running forecast...\")\n",
    "try:\n",
    "    # バッチサイズ1で実行\n",
    "    _ = tfm.forecast(inputs=[input_data[0]], horizon=128)\n",
    "except Exception as e:\n",
    "    # forecastの戻り値処理でエラーが出ても、フックさえ動けばOK\n",
    "    print(f\"Forecast processed (Warning: {e})\")\n",
    "\n",
    "handle.remove()\n",
    "\n",
    "# --- 3. テーブル (DataFrame) 化と表示 ---\n",
    "if 'deep_features' in embeddings_storage:\n",
    "    # Shape: (Batch, Patch_Length, Dim) -> (1, 16, 1280)\n",
    "    emb = embeddings_storage['deep_features'][0]  # バッチ先頭を取り出し\n",
    "    \n",
    "    # DataFrame作成\n",
    "    # 行: パッチ(時間), 列: 次元\n",
    "    df_features = pd.DataFrame(emb)\n",
    "    df_features.index.name = \"Time_Patch_Index\"\n",
    "    df_features.columns.name = \"Feature_Dim\"\n",
    "    \n",
    "    print(f\"\\nFeature Table Shape: {df_features.shape}\")\n",
    "    print(\"=== Feature Matrix (Head) ===\")\n",
    "    \n",
    "    # 大きすぎるので一部を表示 (最初の10列だけなど)\n",
    "    display(df_features.iloc[:, :10].head())\n",
    "    \n",
    "    # 統計情報の確認\n",
    "    print(\"\\n=== Basic Statistics of Features ===\")\n",
    "    display(df_features.describe().iloc[:, :10]) # 記述統計\n",
    "    \n",
    "    # --- (オプション) クラスタリング用データの作成 ---\n",
    "    # このテーブルを使えば、類似度計算などが可能です\n",
    "    # 例: パッチごとの相関行列\n",
    "    corr_matrix = df_features.T.corr()\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', center=0)\n",
    "    plt.title(\"Time Patch Correlation (Similarity)\")\n",
    "    plt.xlabel(\"Patch Time\")\n",
    "    plt.ylabel(\"Patch Time\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Error: Failed to capture features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865db7d2",
   "metadata": {},
   "source": [
    "# 8. 最適化と高速化の検証 (Optimization & Benchmark)\n",
    "\n",
    "TimesFM v2.5 の `compile()` による最適化効果を検証します。\n",
    "モデルの計算グラフを事前に構築・最適化することで、2回目以降の推論速度が大幅に向上する（キャッシュ効果）ことを確認します。\n",
    "\n",
    "**検証項目:**\n",
    "1.  **Compilation Time**: `tfm.compile()` にかかる時間。\n",
    "2.  **Warm-up Inference**: コンパイル後、最初の推論にかかる時間（初期化オーバーヘッドを含む）。\n",
    "3.  **Cached Inference**: 2回目以降の推論にかかる時間（ここが実運用時の速度）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import timesfm\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 設定\n",
    "# =========================\n",
    "BATCH_SIZE = 32\n",
    "CONTEXT_LEN = 512\n",
    "HORIZON_LEN = 128\n",
    "\n",
    "# hookで中間表現を取りたい場合だけ True（ベンチだけなら False 推奨）\n",
    "CAPTURE_ACTIVATIONS = False\n",
    "\n",
    "# 使うチェックポイント\n",
    "# - TimesFM 2.5が使える環境なら 2.5 をデフォルト\n",
    "# - 2.5が無い（=2.0系）なら 2.0 をデフォルト\n",
    "HF_REPO_ID_2P5 = \"google/timesfm-2.5-200m-pytorch\"\n",
    "HF_REPO_ID_2P0 = \"google/timesfm-2.0-500m-pytorch\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ユーティリティ\n",
    "# =========================\n",
    "def sync_cuda():\n",
    "    \"\"\"CUDAの非同期実行で計測がズレるのを防ぐ。\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "def pick_first_tensor(x):\n",
    "    \"\"\"入れ子構造(tuple/list/dict)から最初の torch.Tensor を拾う。無ければ None.\"\"\"\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x\n",
    "    if isinstance(x, (tuple, list)):\n",
    "        for v in x:\n",
    "            t = pick_first_tensor(v)\n",
    "            if t is not None:\n",
    "                return t\n",
    "    if isinstance(x, dict):\n",
    "        for v in x.values():\n",
    "            t = pick_first_tensor(v)\n",
    "            if t is not None:\n",
    "                return t\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_activation_hook(name: str, storage: dict):\n",
    "    \"\"\"\n",
    "    forward hook: outputがtupleでも落ちない版。\n",
    "    あなたのエラー（'tuple' object has no attribute 'detach'）を潰す主役。\n",
    "    \"\"\"\n",
    "    def hook(_module, _inputs, output):\n",
    "        t = pick_first_tensor(output)\n",
    "        if t is None:\n",
    "            return\n",
    "        storage[name] = t.detach().cpu().numpy()\n",
    "    return hook\n",
    "\n",
    "\n",
    "def make_forecast_config(**kwargs):\n",
    "    \"\"\"\n",
    "    timesfm.ForecastConfig があればそれを使う。\n",
    "    互換性のため、受け付けない引数があれば落として再作成。\n",
    "    \"\"\"\n",
    "    ForecastConfig = getattr(timesfm, \"ForecastConfig\", None)\n",
    "    if ForecastConfig is None and hasattr(timesfm, \"configs\"):\n",
    "        ForecastConfig = getattr(timesfm.configs, \"ForecastConfig\", None)\n",
    "    if ForecastConfig is None:\n",
    "        raise RuntimeError(\"ForecastConfig が見つかりません。timesfm のバージョンを確認してください。\")\n",
    "\n",
    "    try:\n",
    "        return ForecastConfig(**kwargs)\n",
    "    except TypeError:\n",
    "        # バージョン差で受け付けないキーがある場合の保険\n",
    "        # まずは per_core_batch_size を落として再試行\n",
    "        kwargs.pop(\"per_core_batch_size\", None)\n",
    "        return ForecastConfig(**kwargs)\n",
    "\n",
    "\n",
    "def load_timesfm_model():\n",
    "    \"\"\"\n",
    "    TimesFM 2.5 API を優先してロード。\n",
    "    2.5クラスが無ければ 2.0 API へフォールバック。\n",
    "    \"\"\"\n",
    "    torch.set_float32_matmul_precision(\"high\")  # 公式例 :contentReference[oaicite:2]{index=2}\n",
    "\n",
    "    if hasattr(timesfm, \"TimesFM_2p5_200M_torch\"):\n",
    "        model = timesfm.TimesFM_2p5_200M_torch.from_pretrained(HF_REPO_ID_2P5)  # 公式例 :contentReference[oaicite:3]{index=3}\n",
    "        api_ver = \"2.5\"\n",
    "        return model, api_ver\n",
    "\n",
    "    # ---- フォールバック: TimesFM 2.0 API（TimesFm + TimesFmHparams） ----\n",
    "    if hasattr(timesfm, \"TimesFm\") and hasattr(timesfm, \"TimesFmHparams\") and hasattr(timesfm, \"TimesFmCheckpoint\"):\n",
    "        model = timesfm.TimesFm(\n",
    "            hparams=timesfm.TimesFmHparams(\n",
    "                backend=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "                per_core_batch_size=BATCH_SIZE,\n",
    "                horizon_len=HORIZON_LEN,\n",
    "                # 2.0系は context_len を持つ（max 2048 推奨） :contentReference[oaicite:4]{index=4}\n",
    "                context_len=2048,\n",
    "                num_layers=50,\n",
    "                use_positional_embedding=False,\n",
    "            ),\n",
    "            checkpoint=timesfm.TimesFmCheckpoint(huggingface_repo_id=HF_REPO_ID_2P0),\n",
    "        )\n",
    "        api_ver = \"2.0\"\n",
    "        return model, api_ver\n",
    "\n",
    "    raise RuntimeError(\"TimesFM のロード方法が見つかりません。timesfm のインストール状況を確認してください。\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# メイン\n",
    "# =========================\n",
    "def main():\n",
    "    print(\"=== Starting Optimization Benchmark ===\")\n",
    "    print(f\"torch: {torch.__version__}\")\n",
    "    print(f\"cuda available: {torch.cuda.is_available()}\")\n",
    "\n",
    "    # ダミーデータ生成（Batch, Length）\n",
    "    # 正弦波を32本用意\n",
    "    benchmark_input = [np.sin(np.linspace(0, 100, CONTEXT_LEN)).astype(np.float32) for _ in range(BATCH_SIZE)]\n",
    "\n",
    "    # モデルロード\n",
    "    tfm, api_ver = load_timesfm_model()\n",
    "    print(f\"Loaded TimesFM API version: {api_ver}\")\n",
    "\n",
    "    # eval相当（内部に torch.nn.Module を持っていれば）\n",
    "    if hasattr(tfm, \"model\") and isinstance(tfm.model, torch.nn.Module):\n",
    "        tfm.model.eval()\n",
    "\n",
    "    # forward hook（任意）\n",
    "    embeddings_storage = {}\n",
    "    hook_handles = []\n",
    "    if CAPTURE_ACTIVATIONS:\n",
    "        # 2.5系は tfm.model が本体モジュールになっていることが多い\n",
    "        target = tfm.model if hasattr(tfm, \"model\") and isinstance(tfm.model, torch.nn.Module) else None\n",
    "        if target is not None:\n",
    "            h = target.register_forward_hook(get_activation_hook(\"tfm.model:first_tensor\", embeddings_storage))\n",
    "            hook_handles.append(h)\n",
    "            print(\"Activation hook enabled (safe for tuple outputs).\")\n",
    "        else:\n",
    "            print(\"Activation hook requested but no torch.nn.Module found; skipping hooks.\")\n",
    "\n",
    "    # 2.5系：compile + ForecastConfig が使える :contentReference[oaicite:5]{index=5}\n",
    "    compile_time = 0.0\n",
    "    if hasattr(tfm, \"compile\"):\n",
    "        print(f\"Compiling model (Batch Size: {BATCH_SIZE})...\")\n",
    "        bench_config = make_forecast_config(\n",
    "            max_context=CONTEXT_LEN,\n",
    "            max_horizon=HORIZON_LEN,\n",
    "            per_core_batch_size=BATCH_SIZE,  # バージョン差で無効なら自動で落とす\n",
    "            normalize_inputs=True,\n",
    "        )\n",
    "\n",
    "        sync_cuda()\n",
    "        t0 = time.perf_counter()\n",
    "        tfm.compile(bench_config)\n",
    "        sync_cuda()\n",
    "        compile_time = time.perf_counter() - t0\n",
    "        print(f\"Compilation Time: {compile_time:.6f} seconds\")\n",
    "    else:\n",
    "        print(\"compile() not available in this TimesFM version; skipping compilation timing.\")\n",
    "\n",
    "    # 推論ベンチ\n",
    "    print(\"Running inference benchmark...\")\n",
    "\n",
    "    def run_once():\n",
    "        # 推論専用モード（autograd無効でオーバーヘッド削減） :contentReference[oaicite:6]{index=6}\n",
    "        with torch.inference_mode():\n",
    "            _ = tfm.forecast(inputs=benchmark_input, horizon=HORIZON_LEN)\n",
    "\n",
    "    # A. 1st Run (Warm-up)\n",
    "    sync_cuda()\n",
    "    t0 = time.perf_counter()\n",
    "    run_once()\n",
    "    sync_cuda()\n",
    "    warmup_time = time.perf_counter() - t0\n",
    "    print(f\"1st Run (Warm-up): {warmup_time:.6f} seconds\")\n",
    "\n",
    "    # B. 2nd Run (Cached)\n",
    "    sync_cuda()\n",
    "    t0 = time.perf_counter()\n",
    "    run_once()\n",
    "    sync_cuda()\n",
    "    optimized_time = time.perf_counter() - t0\n",
    "    print(f\"2nd Run (Cached) : {optimized_time:.6f} seconds\")\n",
    "\n",
    "    # C. Average (Stable)\n",
    "    num_loops = 10\n",
    "    total = 0.0\n",
    "    for _ in range(num_loops):\n",
    "        sync_cuda()\n",
    "        t0 = time.perf_counter()\n",
    "        run_once()\n",
    "        sync_cuda()\n",
    "        total += (time.perf_counter() - t0)\n",
    "\n",
    "    avg_time = total / num_loops\n",
    "    print(f\"Avg Run ({num_loops} loops): {avg_time:.6f} seconds\")\n",
    "\n",
    "    # 可視化\n",
    "    times = [compile_time, warmup_time, optimized_time, avg_time]\n",
    "    labels = ['Compilation', 'Warm-up\\n(1st)', 'Optimized\\n(2nd)', 'Average\\n(Stable)']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(labels, times)\n",
    "\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., h, f\"{h:.6f}s\", ha=\"center\", va=\"bottom\", fontweight=\"bold\")\n",
    "\n",
    "    plt.ylabel(\"Execution Time (seconds)\")\n",
    "    plt.title(f\"TimesFM Speed Benchmark (API {api_ver})\\n(Batch Size: {BATCH_SIZE}, Horizon: {HORIZON_LEN})\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    # 速度向上率\n",
    "    if optimized_time > 0:\n",
    "        speedup = warmup_time / optimized_time\n",
    "        print(f\"\\n>> Speedup Factor (Warm-up / Optimized): {speedup:.2f}x\")\n",
    "\n",
    "    # hook後片付け\n",
    "    for h in hook_handles:\n",
    "        h.remove()\n",
    "\n",
    "    if CAPTURE_ACTIVATIONS:\n",
    "        print(f\"Captured activations keys: {list(embeddings_storage.keys())[:5]} ...\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa24fc",
   "metadata": {},
   "source": [
    "## TimesFM `save_pretrained()` 引数の網羅抽出と、保存結果の差分検証\n",
    "\n",
    "このノートでは、いま使っている `TimesFM` インスタンスの `save_pretrained()` について\n",
    "\n",
    "1) 実際のシグネチャ（引数一覧）を `inspect.signature()` で抽出  \n",
    "2) 主要な引数（例：`max_shard_size`, `variant`）を変えて保存  \n",
    "3) 生成されたファイル一覧・合計サイズ・再ロード可否を比較\n",
    "\n",
    "を自動で行う。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d180d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import timesfm\n",
    "\n",
    "# ===== 設定（フルパス）=====\n",
    "MODEL_LOCAL_DIR = r\"C:\\moinfo\\timesfm_v2.5_local\"\n",
    "MODEL_HF_ID     = \"google/timesfm-2.5-200m-pytorch\"\n",
    "\n",
    "OUT_ROOT = Path(r\"C:\\moinfo\\_artifacts\\timesfm_save_pretrained_matrix_tests\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_model():\n",
    "    if os.path.isdir(MODEL_LOCAL_DIR):\n",
    "        print(f\"[load] local: {MODEL_LOCAL_DIR}\")\n",
    "        return timesfm.TimesFM_2p5_200M_torch.from_pretrained(MODEL_LOCAL_DIR)\n",
    "    print(f\"[load] hf: {MODEL_HF_ID}\")\n",
    "    return timesfm.TimesFM_2p5_200M_torch.from_pretrained(MODEL_HF_ID)\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "# ===== ユーティリティ =====\n",
    "def sha256_file(p: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with p.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def list_files_with_stats(d: Path):\n",
    "    rows = []\n",
    "    for p in sorted(d.rglob(\"*\")):\n",
    "        if p.is_file():\n",
    "            rows.append({\n",
    "                \"path\": str(p.relative_to(d)),\n",
    "                \"bytes\": p.stat().st_size,\n",
    "                \"sha256\": sha256_file(p),\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "def save_and_report(name: str, **kwargs):\n",
    "    out_dir = OUT_ROOT / name\n",
    "    if out_dir.exists():\n",
    "        # 既存があると差分が紛れるので消す\n",
    "        for p in out_dir.rglob(\"*\"):\n",
    "            if p.is_file():\n",
    "                p.unlink()\n",
    "        for p in sorted(out_dir.rglob(\"*\"), reverse=True):\n",
    "            if p.is_dir():\n",
    "                try:\n",
    "                    p.rmdir()\n",
    "                except OSError:\n",
    "                    pass\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"\\n=== EXP: {name} ===\")\n",
    "    print(\"save_dir:\", str(out_dir))\n",
    "    print(\"kwargs   :\", kwargs)\n",
    "\n",
    "    t0 = time.time()\n",
    "    ret = model.save_pretrained(str(out_dir), **kwargs)  # ここが本体\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    files = list_files_with_stats(out_dir)\n",
    "    total = sum(r[\"bytes\"] for r in files)\n",
    "    files_sorted = sorted(files, key=lambda r: r[\"bytes\"], reverse=True)\n",
    "\n",
    "    print(f\"saved_files: {len(files)} total: {total/1024/1024:.2f}MB save_time: {dt:.3f}s\")\n",
    "    print(\"top files:\")\n",
    "    for r in files_sorted[:5]:\n",
    "        print(f\"  - {r['path']}: {r['bytes']/1024/1024:.2f}MB sha256={r['sha256'][:12]}...\")\n",
    "\n",
    "    return {\"name\": name, \"dir\": str(out_dir), \"ret\": ret, \"files\": files, \"total_bytes\": total, \"save_sec\": dt}\n",
    "\n",
    "# ===== 実験メニュー =====\n",
    "# 1) baseline：何も渡さない\n",
    "exp1 = save_and_report(\"baseline_default\")\n",
    "\n",
    "# 2) README（モデルカード）だけ変える：model_card_kwargs\n",
    "# ※ docs上、ModelHubMixin 側が model card を生成するための kwargs です。:contentReference[oaicite:9]{index=9}\n",
    "exp2 = save_and_report(\n",
    "    \"model_card_kwargs_test\",\n",
    "    model_card_kwargs={\n",
    "        \"language\": [\"ja\"],\n",
    "        \"tags\": [\"moinfo-test\", \"timesfm\"],\n",
    "        \"license\": \"apache-2.0\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# 3) config.json だけ変える：config\n",
    "# ※ ここは「再ロード互換」を壊す可能性があるので、まずは“差分が出る”の確認に徹します。\n",
    "exp3 = save_and_report(\n",
    "    \"config_override_test\",\n",
    "    config={\n",
    "        \"_moinfo_note\": \"config override test\",\n",
    "        \"_saved_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "# ===== 差分比較（baseline vs others）=====\n",
    "def diff_from_baseline(base, other):\n",
    "    b = {r[\"path\"]: r for r in base[\"files\"]}\n",
    "    o = {r[\"path\"]: r for r in other[\"files\"]}\n",
    "    all_paths = sorted(set(b) | set(o))\n",
    "\n",
    "    changed = []\n",
    "    for p in all_paths:\n",
    "        if p not in b:\n",
    "            changed.append((p, \"ADDED\"))\n",
    "        elif p not in o:\n",
    "            changed.append((p, \"REMOVED\"))\n",
    "        else:\n",
    "            if b[p][\"sha256\"] != o[p][\"sha256\"] or b[p][\"bytes\"] != o[p][\"bytes\"]:\n",
    "                changed.append((p, \"CHANGED\"))\n",
    "    return changed\n",
    "\n",
    "print(\"\\n=== DIFF vs baseline ===\")\n",
    "for exp in [exp2, exp3]:\n",
    "    changed = diff_from_baseline(exp1, exp)\n",
    "    print(f\"\\n[{exp['name']}] changed_files={len(changed)}\")\n",
    "    for p, st in changed:\n",
    "        print(f\"  - {st}: {p}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "p1 = Path(r\"C:\\moinfo\\_artifacts\\timesfm_save_pretrained_matrix_tests\\baseline_default\\README.md\")\n",
    "p2 = Path(r\"C:\\moinfo\\_artifacts\\timesfm_save_pretrained_matrix_tests\\model_card_kwargs_test\\README.md\")\n",
    "\n",
    "print(\"same?\", p1.read_bytes() == p2.read_bytes())\n",
    "print(\"baseline head:\\n\", p1.read_text(encoding=\"utf-8\", errors=\"ignore\")[:400])\n",
    "print(\"\\nkwargs head:\\n\", p2.read_text(encoding=\"utf-8\", errors=\"ignore\")[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcd3f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from safetensors.torch import save_file\n",
    "\n",
    "OUT_DIR = Path(r\"C:\\moinfo\\_artifacts\\timesfm_fp16_export\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# TimesFM 2.5の内部が model ならそれを使う\n",
    "core = model.model if hasattr(model, \"model\") else None\n",
    "if core is None:\n",
    "    raise RuntimeError(\"内部 torch.nn.Module が見つかりません（model.model が無い）。\")\n",
    "\n",
    "core.eval()\n",
    "\n",
    "# fp16化した state_dict を作る\n",
    "sd = core.state_dict()\n",
    "sd_fp16 = {}\n",
    "for k, v in sd.items():\n",
    "    if torch.is_floating_point(v):\n",
    "        sd_fp16[k] = v.detach().cpu().half()\n",
    "    else:\n",
    "        sd_fp16[k] = v.detach().cpu()\n",
    "\n",
    "out_path = OUT_DIR / \"model.fp16.safetensors\"\n",
    "save_file(sd_fp16, str(out_path))\n",
    "\n",
    "print(\"saved:\", out_path, \"size(MB)=\", out_path.stat().st_size/1024/1024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b67268",
   "metadata": {},
   "source": [
    "## state_dict を保存する（.pt と .safetensors 両対応）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "def _get_torch_module(timesfm_obj):\n",
    "    \"\"\"TimesFMラッパ or nn.Module どちらでも受けて、内部torch.nn.Moduleを返す。\"\"\"\n",
    "    if isinstance(timesfm_obj, torch.nn.Module):\n",
    "        return timesfm_obj\n",
    "    if hasattr(timesfm_obj, \"model\") and isinstance(timesfm_obj.model, torch.nn.Module):\n",
    "        return timesfm_obj.model\n",
    "    raise TypeError(\"torch.nn.Module が見つかりません。timesfm_obj か timesfm_obj.model を確認してください。\")\n",
    "\n",
    "def save_state_dict(\n",
    "    timesfm_obj,\n",
    "    out_path: str,\n",
    "    *,\n",
    "    dtype: str | None = None,   # None / \"fp16\" / \"bf16\" / \"fp32\"\n",
    "    use_safetensors: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    推論・学習で使う「重み」を保存する。\n",
    "    dtype を指定すると、保存前に重みの型を変換して容量を削減できる（例: fp16）。\n",
    "    \"\"\"\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    m = _get_torch_module(timesfm_obj)\n",
    "    sd = m.state_dict()\n",
    "\n",
    "    # dtype変換（容量削減・ただし出力が微妙に変わる可能性あり）\n",
    "    if dtype is not None:\n",
    "        if dtype.lower() == \"fp16\":\n",
    "            cast = torch.float16\n",
    "        elif dtype.lower() == \"bf16\":\n",
    "            cast = torch.bfloat16\n",
    "        elif dtype.lower() == \"fp32\":\n",
    "            cast = torch.float32\n",
    "        else:\n",
    "            raise ValueError(\"dtype は None / 'fp16' / 'bf16' / 'fp32' のみ対応です。\")\n",
    "\n",
    "        sd2 = {}\n",
    "        for k, v in sd.items():\n",
    "            if torch.is_floating_point(v):\n",
    "                sd2[k] = v.detach().cpu().to(cast)\n",
    "            else:\n",
    "                sd2[k] = v.detach().cpu()\n",
    "        sd = sd2\n",
    "    else:\n",
    "        # pickle/safetensorsのため、CPUに移しておくのが安全\n",
    "        sd = {k: v.detach().cpu() for k, v in sd.items()}\n",
    "\n",
    "    if use_safetensors:\n",
    "        from safetensors.torch import save_file\n",
    "        if out_path.suffix.lower() != \".safetensors\":\n",
    "            out_path = out_path.with_suffix(\".safetensors\")\n",
    "        save_file(sd, str(out_path))\n",
    "    else:\n",
    "        if out_path.suffix.lower() != \".pt\":\n",
    "            out_path = out_path.with_suffix(\".pt\")\n",
    "        torch.save(sd, str(out_path))  # PyTorch標準（pickle）\n",
    "\n",
    "    size_mb = out_path.stat().st_size / 1024 / 1024\n",
    "    print(f\"[saved] {out_path} ({size_mb:.2f} MB)\")\n",
    "    return str(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781ec549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例：いま使っている TimesFM インスタンスを model だとする\n",
    "# fp32（元のまま）\n",
    "save_state_dict(model, r\"C:\\moinfo\\_artifacts\\state_dict\\timesfm_2p5_fp32.pt\", dtype=None, use_safetensors=False)\n",
    "\n",
    "# fp16（容量削減）\n",
    "save_state_dict(model, r\"C:\\moinfo\\_artifacts\\state_dict\\timesfm_2p5_fp16.safetensors\", dtype=\"fp16\", use_safetensors=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50486572",
   "metadata": {},
   "source": [
    "## state_dict をロードする（strict/map_location 含む）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3588c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "def load_state_dict(\n",
    "    timesfm_obj,\n",
    "    weight_path: str,\n",
    "    *,\n",
    "    strict: bool = True,\n",
    "    map_location: str = \"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    保存した state_dict をロードしてモデルへ反映する。\n",
    "    strict=True：キー不一致があればエラー（再現性重視）\n",
    "    strict=False：多少違っても読み進める（改造・版違いの暫定対応）\n",
    "    \"\"\"\n",
    "    weight_path = Path(weight_path)\n",
    "    m = _get_torch_module(timesfm_obj)\n",
    "\n",
    "    if weight_path.suffix.lower() == \".safetensors\":\n",
    "        from safetensors.torch import load_file\n",
    "        sd = load_file(str(weight_path))  # safetensorsは安全に読める\n",
    "    else:\n",
    "        sd = torch.load(str(weight_path), map_location=map_location)  # PyTorch標準\n",
    "\n",
    "    missing, unexpected = m.load_state_dict(sd, strict=strict)\n",
    "    print(\"[loaded]\", str(weight_path))\n",
    "    print(\"  missing_keys   =\", len(missing))\n",
    "    print(\"  unexpected_keys=\", len(unexpected))\n",
    "    if len(missing) > 0:\n",
    "        print(\"  sample missing:\", missing[:10])\n",
    "    if len(unexpected) > 0:\n",
    "        print(\"  sample unexpected:\", unexpected[:10])\n",
    "    return missing, unexpected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fb5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 新しく model2 を作る（あなたの既存ロード関数を使う想定）\n",
    "# model2 = load_timesfm_2p5()\n",
    "\n",
    "# fp16を読み込む（注意：ロード後に推論時のdtypeやdeviceの扱いは自分で決める）\n",
    "load_state_dict(model2, r\"C:\\moinfo\\_artifacts\\state_dict\\timesfm_2p5_fp16.safetensors\", strict=True, map_location=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d7004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def save_checkpoint(\n",
    "    timesfm_obj,\n",
    "    out_path: str,\n",
    "    *,\n",
    "    optimizer=None,\n",
    "    scheduler=None,\n",
    "    scaler=None,     # AMP（自動混合精度）を使う場合\n",
    "    step: int | None = None,\n",
    "    epoch: int | None = None,\n",
    "):\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    m = _get_torch_module(timesfm_obj)\n",
    "\n",
    "    ckpt = {\n",
    "        \"model_state_dict\": {k: v.detach().cpu() for k, v in m.state_dict().items()},\n",
    "        \"step\": step,\n",
    "        \"epoch\": epoch,\n",
    "    }\n",
    "    if optimizer is not None:\n",
    "        ckpt[\"optimizer_state_dict\"] = optimizer.state_dict()\n",
    "    if scheduler is not None:\n",
    "        ckpt[\"scheduler_state_dict\"] = scheduler.state_dict()\n",
    "    if scaler is not None:\n",
    "        ckpt[\"scaler_state_dict\"] = scaler.state_dict()\n",
    "\n",
    "    torch.save(ckpt, str(out_path))\n",
    "    print(f\"[saved checkpoint] {out_path} ({out_path.stat().st_size/1024/1024:.2f} MB)\")\n",
    "    return str(out_path)\n",
    "\n",
    "def load_checkpoint(\n",
    "    timesfm_obj,\n",
    "    ckpt_path: str,\n",
    "    *,\n",
    "    optimizer=None,\n",
    "    scheduler=None,\n",
    "    scaler=None,\n",
    "    strict: bool = True,\n",
    "    map_location: str = \"cpu\",\n",
    "):\n",
    "    ckpt = torch.load(ckpt_path, map_location=map_location)\n",
    "    m = _get_torch_module(timesfm_obj)\n",
    "\n",
    "    missing, unexpected = m.load_state_dict(ckpt[\"model_state_dict\"], strict=strict)\n",
    "\n",
    "    if optimizer is not None and \"optimizer_state_dict\" in ckpt:\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "    if scheduler is not None and \"scheduler_state_dict\" in ckpt:\n",
    "        scheduler.load_state_dict(ckpt[\"scheduler_state_dict\"])\n",
    "    if scaler is not None and \"scaler_state_dict\" in ckpt:\n",
    "        scaler.load_state_dict(ckpt[\"scaler_state_dict\"])\n",
    "\n",
    "    print(\"[loaded checkpoint]\", ckpt_path)\n",
    "    print(\"  step =\", ckpt.get(\"step\"), \"epoch =\", ckpt.get(\"epoch\"))\n",
    "    print(\"  missing_keys =\", len(missing), \"unexpected_keys =\", len(unexpected))\n",
    "    return ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a63a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import timesfm\n",
    "\n",
    "# --- 設定（あなたのノートに合わせて） ---\n",
    "BATCH_SIZE  = 8\n",
    "CONTEXT_LEN = 512\n",
    "HORIZON_LEN = 128\n",
    "\n",
    "# 既に作ってある前提：\n",
    "# model  = load_timesfm_2p5()           # fp32（元）\n",
    "# model2 = load_timesfm_2p5(); load_state_dict(model2, fp16_path)  # fp16重みをロード済み\n",
    "\n",
    "# --- compile を強制（両方に必要） ---\n",
    "def compile_timesfm(m):\n",
    "    cfg = timesfm.ForecastConfig(\n",
    "        max_context=CONTEXT_LEN,\n",
    "        max_horizon=HORIZON_LEN,\n",
    "        per_core_batch_size=BATCH_SIZE,\n",
    "        normalize_inputs=True,\n",
    "        # XReg（forecast_with_covariates）も使うなら True のままが安全\n",
    "        return_backcast=True,\n",
    "    )\n",
    "    m.compile(cfg)\n",
    "    return cfg\n",
    "\n",
    "print(\"Compiling model (fp32) ...\")\n",
    "cfg1 = compile_timesfm(model)\n",
    "\n",
    "print(\"Compiling model2 (fp16 weights loaded) ...\")\n",
    "cfg2 = compile_timesfm(model2)\n",
    "\n",
    "# --- 入力 ---\n",
    "inputs = [np.sin(np.linspace(0, 30, CONTEXT_LEN)).astype(np.float32) for _ in range(BATCH_SIZE)]\n",
    "\n",
    "# --- 予測（互換：horizon引数 or freq引数の差分を吸収） ---\n",
    "def forecast_point_only(m):\n",
    "    try:\n",
    "        y, _ = m.forecast(horizon=HORIZON_LEN, inputs=inputs)\n",
    "    except TypeError:\n",
    "        y, _ = m.forecast(inputs=inputs, freq=[0]*len(inputs))\n",
    "    y = np.asarray(y)\n",
    "    # return_backcast=True の場合 (B, backcast+horizon) なので末尾だけ取る\n",
    "    return y[:, -HORIZON_LEN:]\n",
    "\n",
    "# --- 差分評価（fp32 vs fp16）---\n",
    "y32 = forecast_point_only(model)\n",
    "y16 = forecast_point_only(model2)\n",
    "\n",
    "abs_err = np.abs(y32 - y16)\n",
    "max_abs = float(abs_err.max())\n",
    "mae = float(abs_err.mean())\n",
    "rmse = float(np.sqrt(((y32 - y16) ** 2).mean()))\n",
    "\n",
    "den = np.maximum(np.abs(y32), 1e-6)\n",
    "rel = abs_err / den\n",
    "max_rel = float(rel.max())\n",
    "mean_rel = float(rel.mean())\n",
    "\n",
    "print(\"\\n=== fp32 vs fp16 difference (forecast horizon only) ===\")\n",
    "print(\"max_abs =\", max_abs)\n",
    "print(\"mae     =\", mae)\n",
    "print(\"rmse    =\", rmse)\n",
    "print(\"max_rel =\", max_rel)\n",
    "print(\"mean_rel=\", mean_rel)\n",
    "\n",
    "# --- 速度（簡易）---\n",
    "def bench(m, loops=10):\n",
    "    _ = forecast_point_only(m)  # warm-up\n",
    "    t0 = time.time()\n",
    "    for _ in range(loops):\n",
    "        _ = forecast_point_only(m)\n",
    "    return (time.time() - t0) / loops\n",
    "\n",
    "t32 = bench(model, loops=10)\n",
    "t16 = bench(model2, loops=10)\n",
    "\n",
    "print(\"\\n=== speed (sec / call) ===\")\n",
    "print(\"fp32:\", t32)\n",
    "print(\"fp16:\", t16)\n",
    "print(\"speedup(fp32/fp16):\", (t32 / t16) if t16 > 0 else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timesfm\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# ====== 設定 ======\n",
    "BATCH_SIZE  = 8\n",
    "CONTEXT_LEN = 512\n",
    "HORIZON_LEN = 128\n",
    "\n",
    "# ====== dtype 分布の可視化 ======\n",
    "def summarize_param_dtypes(timesfm_obj):\n",
    "    core = timesfm_obj.model if hasattr(timesfm_obj, \"model\") else timesfm_obj\n",
    "    if not isinstance(core, torch.nn.Module):\n",
    "        raise TypeError(\"内部 torch.nn.Module が見つかりません（timesfm_obj.model を確認）。\")\n",
    "\n",
    "    d = {}\n",
    "    for _, v in core.state_dict().items():\n",
    "        if torch.is_floating_point(v):\n",
    "            key = str(v.dtype)\n",
    "            d[key] = d.get(key, 0) + v.numel()\n",
    "\n",
    "    total = sum(d.values()) or 1\n",
    "    print(\"float param dtype distribution (by numel):\")\n",
    "    for k in sorted(d, key=lambda x: -d[x]):\n",
    "        print(f\"  {k}: {d[k] / total * 100:.2f}%\")\n",
    "\n",
    "# ====== compile 設定 ======\n",
    "def compile_cfg():\n",
    "    return timesfm.ForecastConfig(\n",
    "        max_context=CONTEXT_LEN,\n",
    "        max_horizon=HORIZON_LEN,\n",
    "        per_core_batch_size=BATCH_SIZE,\n",
    "        normalize_inputs=True,\n",
    "        return_backcast=True,\n",
    "    )\n",
    "\n",
    "# ====== fp16 化（in-place） ======\n",
    "def to_fp16_inplace(timesfm_obj):\n",
    "    core = timesfm_obj.model if hasattr(timesfm_obj, \"model\") else timesfm_obj\n",
    "    if not isinstance(core, torch.nn.Module):\n",
    "        raise TypeError(\"内部 torch.nn.Module が見つかりません（timesfm_obj.model を確認）。\")\n",
    "    core.eval()\n",
    "    core.half()\n",
    "    return timesfm_obj\n",
    "\n",
    "# ====== 予測（末尾128だけ） ======\n",
    "inputs = [np.sin(np.linspace(0, 30, CONTEXT_LEN)).astype(np.float32) for _ in range(BATCH_SIZE)]\n",
    "\n",
    "def forecast_point_only(m):\n",
    "    y, _ = m.forecast(horizon=HORIZON_LEN, inputs=inputs)\n",
    "    y = np.asarray(y)\n",
    "    return y[:, -HORIZON_LEN:]\n",
    "\n",
    "def bench(m, loops=10):\n",
    "    _ = forecast_point_only(m)  # warm-up\n",
    "    t0 = time.time()\n",
    "    for _ in range(loops):\n",
    "        _ = forecast_point_only(m)\n",
    "    return (time.time() - t0) / loops\n",
    "\n",
    "# ====== 実行：fp16化→compile→検証 ======\n",
    "print(\"=== BEFORE fp16 cast ===\")\n",
    "summarize_param_dtypes(model2)\n",
    "\n",
    "print(\"\\nCasting model2 to fp16 ...\")\n",
    "to_fp16_inplace(model2)\n",
    "\n",
    "print(\"\\nCompiling model2 after fp16 cast ...\")\n",
    "model2.compile(compile_cfg())\n",
    "\n",
    "print(\"\\n=== AFTER fp16 cast ===\")\n",
    "summarize_param_dtypes(model2)\n",
    "\n",
    "# 速度だけ軽く測る（fp16が本当に効いてれば変化が出る可能性）\n",
    "t16 = bench(model2, loops=10)\n",
    "print(\"\\nfp16 model2 sec/call:\", t16)\n",
    "\n",
    "# 参考：GPU確認（使えるなら fp16の恩恵が出やすい）\n",
    "print(\"\\ncuda available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"gpu:\", torch.cuda.get_device_name(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee326080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if hasattr(model2, \"model\") and isinstance(model2.model, torch.nn.Module):\n",
    "    model2.model = model2.model.half()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16fc99",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd854b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timesfm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. モデルのロード (TimesFM 2.5 - 200Mパラメータ PyTorch版)\n",
    "# GPUが利用可能な場合は自動的にGPUを使用します\n",
    "print(\"Loading model...\")\n",
    "model = timesfm.TimesFM_2p5_200M_torch.from_pretrained(\n",
    "    \"google/timesfm-2.5-200m-pytorch\"\n",
    ")\n",
    "\n",
    "# 2. 予測設定のコンパイル (高速化のため)\n",
    "# max_context: 入力の最大長 (これより長い系列はトリミング)\n",
    "# max_horizon: 予測したい未来の最大ステップ数\n",
    "config = timesfm.ForecastConfig(\n",
    "    max_context=512,       # 入力系列の最大長\n",
    "    max_horizon=128,       # 予測期間の長さ\n",
    "    per_core_batch_size=1, # バッチサイズ\n",
    ")\n",
    "model.compile(config)\n",
    "\n",
    "# 3. ダミーデータの作成 (正弦波など)\n",
    "# 実際にはPandas DataFrameやNumPy配列のリストを渡します\n",
    "t = np.linspace(0, 20, 512)\n",
    "input_signal = np.sin(t) * t  # 振幅が大きくなる正弦波\n",
    "inputs = [input_signal]       # リスト形式で複数の時系列を渡せます\n",
    "\n",
    "# 4. 予測の実行\n",
    "print(\"Forecasting...\")\n",
    "# freq: 頻度 (0:高頻度/不明, 1:中頻度, 2:低頻度)。v2.5では自動推論も可。\n",
    "point_forecast, quantile_forecast = model.forecast(\n",
    "    inputs=inputs,\n",
    "    #freq=[0],  # 0は一般的な時系列(秒, 分, 時間, 日など)を指します\n",
    "    horizon=128\n",
    ")\n",
    "\n",
    "# 5. 結果の表示\n",
    "print(f\"Input shape: {inputs[0].shape}\")\n",
    "print(f\"Forecast shape: {point_forecast.shape}\")\n",
    "print(f\"First 5 predictions: {point_forecast[0, :5]}\")\n",
    "\n",
    "# (オプション) 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.arange(512), inputs[0], label=\"History\")\n",
    "plt.plot(np.arange(512, 512+128), point_forecast[0], label=\"Forecast\")\n",
    "plt.legend()\n",
    "plt.title(\"TimesFM Forecast Sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a719a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e832374448145bfbdb1ee88c314ef6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/475 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded.\n",
      "trainable params: 4,712,448 || all params: 236,001,728 || trainable%: 1.9968\n",
      "Starting training loop...\n",
      "Epoch 1: Loss = 1.5212\n",
      "Epoch 2: Loss = 1.5057\n",
      "Epoch 3: Loss = 1.4902\n",
      "Finetuning finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from timesfm import TimesFM_2p5_200M_torch\n",
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "# 1. モデルのロード\n",
    "print(\"Loading model...\")\n",
    "tfm = TimesFM_2p5_200M_torch.from_pretrained(\"google/timesfm-2.5-200m-pytorch\")\n",
    "\n",
    "# 2. モデル本体の取り出し\n",
    "# 【重要】ライブラリの仕様上、tfm.model を直接書き換えるとクラス全体に影響するため\n",
    "# 念のため構造確認だけ行い、get_peft_model はこのインスタンスに対して適用します。\n",
    "pytorch_model = tfm.model\n",
    "pytorch_model.train()\n",
    "\n",
    "# 3. LoRA設定\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=\"all-linear\",\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# 4. LoRA適用\n",
    "# ※ここで pytorch_model が書き換わります\n",
    "model = get_peft_model(pytorch_model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# --- 以降、学習ループ ---\n",
    "# ...\n",
    "# 3. ダミーデータと学習ループの準備\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 【修正ポイント】\n",
    "# TimesFMの入力パッチサイズ (v2.5は 32)\n",
    "patch_len = 32\n",
    "\n",
    "# 入力データを (Batch, Num_Patches, Patch_Len) に変形します\n",
    "# 512ステップ / 32 = 16パッチ\n",
    "train_inputs = torch.randn(32, 512).reshape(32, -1, patch_len).to(tfm.model.device)\n",
    "train_masks = torch.zeros(32, 512).reshape(32, -1, patch_len).to(tfm.model.device)\n",
    "\n",
    "# ターゲットデータ\n",
    "# 出力次元に合わせてターゲットを用意 (簡易的な例)\n",
    "# TimesFMの出力は (Batch, Num_Patches, Output_Dim) です\n",
    "# Output_Dim = 1280 (hidden_dims と同じ)\n",
    "targets = torch.randn(32, 16, 1280).to(tfm.model.device)\n",
    "\n",
    "# 4. 学習ループ (簡易版)\n",
    "print(\"Starting training loop...\")\n",
    "for epoch in range(3):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forwardパス\n",
    "    # output: (input_embeddings, output_embeddings, output_ts, output_quantiles)\n",
    "    outputs, _ = model(train_inputs, train_masks)\n",
    "    \n",
    "    # ここでは出力埋め込み(output_embeddings)をターゲットと比較する例\n",
    "    # 実際には output_ts (予測値のlogits) など、目的に応じた出力を使用します\n",
    "    output_embeddings = outputs[1] # Shape: (32, 16, 1280)\n",
    "    \n",
    "    loss = criterion(output_embeddings, targets)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "print(\"Finetuning finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71730d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moinfo_timesfm_ext import FineTuneConfig, finetune_from_csv, make_dummy_train_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0873989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/moinfo/data/train.csv')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moinfo_timesfm_ext import make_dummy_train_csv\n",
    "make_dummy_train_csv(r\"C:\\moinfo\\data\\train.csv\", n_points=40000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec5fa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Some weights of the model checkpoint at C:\\moinfo\\timesfm_v2.5_local were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
      "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at C:\\moinfo\\timesfm_v2.5_local and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "from moinfo_timesfm_ext import FineTuneConfig, finetune_from_csv\n",
    "\n",
    "cfg = FineTuneConfig(\n",
    "    model_path=r\"C:\\moinfo\\timesfm_v2.5_local\",   # or r\"C:\\moinfo\\timesfm_hf_local\"\n",
    "    csv_path=r\"C:\\moinfo\\data\\train.csv\",\n",
    "    value_col=\"y\",\n",
    "    series_id_col=None,    # 多系列なら \"series_id\" 等\n",
    "    context_len=512,\n",
    "    horizon_len=128,\n",
    "    batch_size=8,\n",
    "    epochs=3,\n",
    "    lr=1e-4,\n",
    "    output_dir=r\"C:\\moinfo\\_artifacts\\timesfm_finetuned\",\n",
    "    device=\"auto\",\n",
    "    dtype=\"auto\",\n",
    ")\n",
    "\n",
    "out_dir = finetune_from_csv(cfg)\n",
    "out_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a738ca95",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FineTuneConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      2\u001b[39m Path(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmoinfo\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mtrain.csv\u001b[39m\u001b[33m\"\u001b[39m).exists()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m cfg = \u001b[43mFineTuneConfig\u001b[49m(\n\u001b[32m      4\u001b[39m     model_path=\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmoinfo\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mtimesfm_v2.5_local\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     csv_path=\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmoinfo\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m_artifacts\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mtrain.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     value_col=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'FineTuneConfig' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path(r\"C:\\moinfo\\data\\train.csv\").exists()\n",
    "cfg = FineTuneConfig(\n",
    "    model_path=r\"C:\\moinfo\\timesfm_v2.5_local\",\n",
    "    csv_path=r\"C:\\moinfo\\_artifacts\\train.csv\",\n",
    "    value_col=\"y\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de1b68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuneConfig(model_path='C:\\\\moinfo\\\\timesfm_v2.5_local', csv_path='C:\\\\moinfo\\\\_artifacts\\\\train.csv', value_col='y', series_id_col=None, time_col=None, freq_id=0, context_len=512, horizon_len=128, samples_per_epoch=20000, batch_size=8, epochs=3, lr=0.0001, weight_decay=0.01, grad_clip_norm=1.0, seed=42, num_workers=0, output_dir='.\\\\timesfm_finetuned', device='auto', dtype='auto')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaiseki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
